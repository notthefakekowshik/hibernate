<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>Cryostat 2.2's new JMX credentials keyring</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/07/cryostat-22s-new-jmx-credentials-keyring" /><author><name>Andrew Azores</name></author><id>62f88e3f-c9bc-4983-86b3-49954cdd7765</id><updated>2022-12-07T07:00:01Z</updated><published>2022-12-07T07:00:01Z</published><summary type="html">&lt;p&gt;An important security enhancement for &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; applications is now available through &lt;a href="https://www.oracle.com/technical-resources/articles/javase/jmx.html"&gt;Java Management Extensions&lt;/a&gt; (JMX), using open source &lt;a href="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u"&gt;JDK Flight Recorder&lt;/a&gt; (JFR) management with &lt;a href="https://cryostat.io"&gt;Cryostat&lt;/a&gt;. (Cryostat is a container-native JVM application that provides a secure API for profiling and monitoring containers with JFR.) This article explains how the new JMX credentials keyring offers an alternative credential management system.&lt;/p&gt; &lt;h2&gt;How the JMX credentials keyring works&lt;/h2&gt; &lt;p&gt;If applications are configured to require JMX authentication for incoming connections, Cryostat must know what those credentials are for any application it needs to connect to. Cryostat connects to the target application in order to start, list, or stop flight recordings, copy JFR data to a local file, get information about JFR event types and templates, etc.&lt;/p&gt; &lt;p&gt;Before Cryostat 2.2, connections to an application through JMX would include an &lt;code&gt;X-JMX-Authorization&lt;/code&gt; header. This header's value would be the JMX credentials required by the target application, so that Cryostat could pass the authentication challenge and connect to the target. The credentials passed in this way weren't stored by Cryostat persistently; they were held in memory just long enough to establish the JMX connection. If you set up your Cryostat installation to use HTTPS and configured your target application to use JMX over SSL/TLS, these credentials were always encrypted while being transmitted.&lt;/p&gt; &lt;p&gt;Cryostat 2.2 adds a keyring to store JMX credentials for your applications. Credentials stored in this way are encrypted at rest using a user-provided passphrase supplied to Cryostat via the &lt;code&gt;CRYOSTAT_JMX_CREDENTIALS_DB_PASSWORD&lt;/code&gt; environment variable.&lt;/p&gt; &lt;p&gt;When attempting to open a JMX connection to a target, Cryostat first checks for the &lt;code&gt;X-JMX-Authorization&lt;/code&gt; header. If there is none, Cryostat checks the keyring database for credentials matching the target, decrypts them using the passphrase, and establishes the JMX connection. Again, if your Cryostat installation is set up with HTTPS and your target uses JMX over SSL/TLS, these JMX credentials are always encrypted in flight, and now they're encrypted at rest within the keyring.&lt;/p&gt; &lt;h2&gt;Advantages of the keyring for microservices&lt;/h2&gt; &lt;p&gt;You might be wondering what I meant by "credentials matching this target" in the previous paragraph. Older versions of Cryostat required the user to define credentials on a per-target basis. Each JMX credential username/password pair was tied to one specific target connection URL. This works fine if your applications are deployed as long-lived "pets" with stable IP addresses, but is not very useful if your applications are deployed as &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservice&lt;/a&gt; "cattle," where the URL to one specific replica or instance is not particularly meaningful.&lt;/p&gt; &lt;p&gt;For this reason, credentials stored in Cryostat 2.2's JMX keyring are no longer tied to specific target connection URLs. Instead, they reuse the same &lt;em&gt;match expression&lt;/em&gt; concept that was previously introduced for Cryostat &lt;a href="https://developers.redhat.com/articles/2022/05/11/how-build-automated-jfr-rules-cryostat-21s-new-ui"&gt;automated rules&lt;/a&gt;. To recap, match expressions are small snippets of Java-like code, where a representation of a target application is passed and available as a target object reference. The expression evaluates various properties of the target object to determine whether the automated rule or the JMX credentials should apply to that target.&lt;/p&gt; &lt;p&gt;The most reliable way to make sure JMX credentials work using this system is to copy and paste the match expressions from your automated rules definitions and apply them to the JMX credentials, so that the rules and credentials apply to the same set of target applications.&lt;/p&gt; &lt;h2&gt;Additional considerations for using JMX credentials with Cryostat&lt;/h2&gt; &lt;p&gt;Because the connection asking for the JMX credentials challenges the target applications to which it connects, and not Cryostat itself, Cryostat is required to store the whole credential and not just a salted hash of it. Storage operates much like the login keyring you might be familiar with on your personal computer, or a password manager you use for storing your logins for online accounts.&lt;/p&gt; &lt;p&gt;An additional enhancement in Cryostat 2.2 lets you define your JMX credentials &lt;em&gt;after&lt;/em&gt; creating an automated rule. Previously, if an automated rule failed to activate for a target application—due to JMX authentication failure, for example—the rule's actions wouldn't trigger for that target application at all. To make the connection work, after you added the credentials, you had to either delete and recreate the rule or restart the application. Now, if you add JMX credentials to the keyring after the fact, your automated rules will re-trigger and attempt to perform their actions against the relevant target applications.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/07/cryostat-22s-new-jmx-credentials-keyring" title="Cryostat 2.2's new JMX credentials keyring"&gt;Cryostat 2.2's new JMX credentials keyring&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Andrew Azores</dc:creator><dc:date>2022-12-07T07:00:01Z</dc:date></entry><entry><title>How to implement single sign-out in Keycloak with Spring Boot</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/07/how-implement-single-sign-out-keycloak-spring-boot" /><author><name>Muhammad Edwin</name></author><id>136eb72c-0401-4acd-b078-e1c1c47fa920</id><updated>2022-12-07T07:00:00Z</updated><published>2022-12-07T07:00:00Z</published><summary type="html">&lt;p&gt;Single sign-on is often implemented with &lt;a href="https://www.keycloak.org"&gt;Keycloak&lt;/a&gt;. Few people know that Keycloak can also implement single sign-out, where logging out from one application causes Keycloak to log the user out of other applications. This article demonstrates how to enable single sign-out to clean up active sessions for security purposes. We implement these capabilities in &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/spring-boot"&gt;Spring Boot&lt;/a&gt;, but the principles apply to any language.&lt;/p&gt; &lt;h2&gt;Single sign-on and single sign-out&lt;/h2&gt; &lt;p&gt;Most users are familiar with single sign-on. Once the user logs in to one application, they no longer need to log in when using other applications on the same service. Figure 1 illustrates the benefits of single sign-on with two different applications, each requiring user authentication before gaining access.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/signon.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/signon.png?itok=Yf5Fm0B8" width="600" height="257" alt="A diagram of the single sign-on process." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Single sign-on allows a user to log in just once to access multiple applications. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Single sign-on works as follows:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;The user visits Application 01's URL and presses the login button.&lt;/li&gt; &lt;li&gt;The Keycloak login page pops up, prompting the user to log in.&lt;/li&gt; &lt;li&gt;The user is redirected to Application 01's landing page when successfully logged in.&lt;/li&gt; &lt;li&gt;Users who visit Application 02's URL within a reasonable amount of time don't have to log in again.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;In single sign-out, the user logs out from either application and is logged out from the other automatically, almost immediately. There are several ways to achieve this logout mechanism, such as through &lt;a href="https://www.keycloak.org/docs/latest/server_admin/#_oidc-logout"&gt;OpenID Connect&lt;/a&gt; (OIDC).&lt;/p&gt; &lt;h2&gt;Back-channel vs. front-channel logout&lt;/h2&gt; &lt;p&gt;Before proceeding, you should understand the difference between a back-channel and a front-channel logout. This article implements back-channel logout because it is less subject to problems.&lt;/p&gt; &lt;p&gt;A back-channel logout takes place between Keycloak and its clients. Keycloak detects a user's logout and sends a request containing a logout token to all clients where the user is logged in. The important aspect of back-channel is that it does not rely on a browser. Figure 2 illustrates this operation.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/signout.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/signout.png?itok=6mSmAsHI" width="600" height="250" alt="Back-channel logout ensures a clean single sign-out by relying on communication between Keycloak and clients." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Back-channel logout ensures a clean single sign-out by relying on communication between Keycloak and clients. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Back-channel logout operates as follows:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;The user presses the logout button in Application 01.&lt;/li&gt; &lt;li&gt;Application 01 clears out the user's session while informing Keycloak that the user is logging out.&lt;/li&gt; &lt;li&gt;Keycloak invokes Application 02's logout endpoint, asking it to remove the user's session.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;In contrast, a front-channel logout relies on the browser with an iframe in the browser window that contains the application's logout URL within Keycloak's logout page. Figure 3 illustrates the intended operation.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/multi_1.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/multi_1.png?itok=-8WVNIe0" width="600" height="264" alt="Front-channel logout relies on the browser to carry out single sign-out." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Front-channel logout relies on the browser to carry out single sign-out. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Front-channel logout operates as follows:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;The user goes to Keycloak's logout URL and presses the logout button.&lt;/li&gt; &lt;li&gt;The user's browser triggers a logout from the Application 01 URL from an iframe.&lt;/li&gt; &lt;li&gt;Almost simultaneously, the browser triggers a logout from the Application 02 URL from another iframe within the same page.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 4 displays a typical user interface for a Keycloak front-channel logout.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screen.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screen.png?itok=FYGeMesc" width="600" height="388" alt="Keycloak displays a logout screen in the browser." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Keycloak displays a logout screen in the browser. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Various surprises, such as the browser's security policy blocking requests, might happen in a front-channel logout. Therefore, this article implements back-channel logout. We'll see how to configure it and how applications can handle Keycloak's logout API requests. For this example, we use a standalone Keycloak instance listening at port 8080 and a Spring Boot application listening at port 8081.&lt;/p&gt; &lt;h2&gt;Keycloak configuration&lt;/h2&gt; &lt;p&gt;First, you need to open a browser and create a client on Keycloak admin page. Figure 5 displays the screen where you can do this.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/create_3.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/create_3.png?itok=ob0g6ge2" width="600" height="142" alt="The Clients menu offers a Create button to create a Keycloak client." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: The Clients menu offers a Create button to create a Keycloak client. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Set the Client ID to &lt;code&gt;external-client&lt;/code&gt; and the protocol to &lt;code&gt;openid-connect&lt;/code&gt;. Press the &lt;strong&gt;Save&lt;/strong&gt; button (Figure 6).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/save.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/save.png?itok=S9jN2XNd" width="600" height="161" alt="After entering basic information, click Save to create a Keycloak client." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: After entering basic information, click Save to create a Keycloak client. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;You can now configure the new Keycloak Client. Use the settings in Table 1.&lt;/p&gt; &lt;table cellspacing="0" width="591"&gt;&lt;caption&gt;Table 1: Configuration settings for a Keycloak client.&lt;/caption&gt; &lt;tbody&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Client ID&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;external-client&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Enabled&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Client protocol&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;openid-connect&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Access type&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;confidential&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Standard flow enabled&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Direct access grants enabled&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Valid redirect URIs&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;http://localhost:8081/*&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Base URL&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;http://localhost:8081&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Backchannel logout URL&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;http://localhost:8081/sso-logout&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Backchannel logout session required&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt; &lt;p&gt;Backchannel logout revokes offline sessions&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;ON&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Press the &lt;strong&gt;Save&lt;/strong&gt; button to store your configuration.&lt;/p&gt; &lt;h2&gt;Application configuration&lt;/h2&gt; &lt;p&gt;Now create a simple Spring Boot application, starting with a &lt;code&gt;pom.xml&lt;/code&gt; file shown as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.edw&lt;/groupId&gt; &lt;artifactId&gt;keycloak-backchannel-logout&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.keycloak.bom&lt;/groupId&gt; &lt;artifactId&gt;keycloak-adapter-bom&lt;/artifactId&gt; &lt;version&gt;19.0.2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- spring boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.keycloak&lt;/groupId&gt; &lt;artifactId&gt;keycloak-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring security --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.keycloak&lt;/groupId&gt; &lt;artifactId&gt;keycloak-spring-security-adapter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- storing session in external db --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.18&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-jdbc&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Also, create an &lt;code&gt;application.properties&lt;/code&gt; file. For this sample application, I'm using MySQL. So I need to put MySQL credentials here:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-ini"&gt;### server port server.port=8081 spring.application.name=Keycloak for Backchannel ### Keycloak Configuration keycloak.auth-server-url=http://localhost:8080/auth/ keycloak.realm=external keycloak.resource=external-client keycloak.public-client=false keycloak.bearer-only=false keycloak.principal-attribute=preferred_username keycloak.credentials.secret=xxxxxxxxx keycloak.use-resource-role-mappings=true keycloak.confidential-port=8081 keycloak.ssl-required=none spring.main.allow-bean-definition-overriding=true logging.level.root=warn logging.level.com.edw=debug server.forward-headers-strategy=NATIVE spring.session.jdbc.flush-mode=on_save spring.session.jdbc.initialize-schema=always spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://127.0.0.1:3306/db_session spring.datasource.username=root spring.datasource.password=password&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, you need to create a database named &lt;code&gt;db_session&lt;/code&gt; containing two tables. These tables are needed to maintain the application sessions, especially if this application has multiple instances:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-sql"&gt;create table db_session.spring_session ( PRIMARY_ID char(36) not null primary key, SESSION_ID char(36) not null, CREATION_TIME bigint not null, LAST_ACCESS_TIME bigint not null, MAX_INACTIVE_INTERVAL int not null, EXPIRY_TIME bigint not null, PRINCIPAL_NAME varchar(100) null, constraint SPRING_SESSION_IX1 unique (SESSION_ID) ); create index SPRING_SESSION_IX2 on db_session.spring_session (EXPIRY_TIME); create index SPRING_SESSION_IX3 on db_session.spring_session (PRINCIPAL_NAME); create table db_session.spring_session_attributes ( SESSION_PRIMARY_ID char(36) not null, ATTRIBUTE_NAME varchar(200) not null, ATTRIBUTE_BYTES blob not null, primary key (SESSION_PRIMARY_ID, ATTRIBUTE_NAME), constraint SPRING_SESSION_ATTRIBUTES_FK foreign key (SESSION_PRIMARY_ID) references db_session.spring_session (PRIMARY_ID) on delete cascade );&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Storing HTTP sessions in your database might negatively impact your application's performance. Therefore, consider other session storing mechanisms for production deployment, such as &lt;a href="https://infinispan.org"&gt;Infinispan&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Once you set up your database, you can create your application's logout mechanism. But first, you must understand how the Keycloak logout mechanism works and the parameters available for logging out.&lt;/p&gt; &lt;p&gt;Basically, every time a client triggers a logout to Keycloak, Keycloak issues a REST API call to all clients it has registered, instructing the clients to log out their sessions for the corresponding user. The REST API call resembles the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-ini"&gt;POST /sso-logout HTTP/1.1 Content-Length: 920 Content-Type: application/x-www-form-urlencoded Host: localhost:8081 Connection: Keep-Alive Accept-Encoding: gzip,deflate logout_token=eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJaMHl nYnpDZzJFSWstX0hLbWNtbllodk91RmpaazZ5ZG9mek5BNF8xQnNzIn0.eyJpYXQiOjE 2NjYzNjI4MTksImp0aSI6IjEyYjRmNWY5LWJhZDYtNDQ4MS1hMGUzLWRmMjEzN2U5MmUxY iIsImlzcyI6Imh0dHA6Ly9sb2NhbGhvc3Q6ODA4MC9hdXRoL3JlYWxtcy9leHRlcm5hbCI sImF1ZCI6ImV4dGVybmFsLWNsaWVudCIsInN1YiI6IjRhMzI0ODY0LTkwNDUtNGY2Mi05N jE1LTc5MTdlZDg1NTk1MyIsInR5cCI6IkxvZ291dCIsInNpZCI6ImRkY2ZiZjc0LTYxZG EtNGViNS1iZjBiLTM4MTAyYzdiMzUzNCIsImV2ZW50cyI6eyJodHRwOi8vc2NoZW1hcy 5vcGVuaWQubmV0L2V2ZW50L2JhY2tjaGFubmVsLWxvZ291dCI6e30sInJldm9rZV9vZmZs aW5lX2FjY2VzcyI6dHJ1ZX19.LE34JQnUL2jZKuwlHwgeDnBNnBiacfvJJYpK7_B2bMfMe SUmmOLQ6M3yRlt3nOT4r-AqkStwwFeUA6Io8iuDcQ87eBwoDEYqyJEV9DDduEW8dx8KNMA Tqh_dQFgvq_aqk8P0U2Ap_DjZCCOTtgXTo3solavq2eL2shWLHni5uvSYpY8DLg73SH-n WRp9j2_rjuVGupwSDTmTzftC9zN6_KcURTLgpal9UWr40kSbIa5knSbftcBjzTanLJynR xfX1LckzCine9533h_HQHwqd-LAD3-SFRIkZeMVvv3-BVVubtyXL6VGdB-XLokzRGGh2j d8sgMnEtqNFa8Ih3Iw0A&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The content of the logout token is a JSON web token (JWT) with a session ID variable (sid) which matches the session ID from the first JWT token granted to a user when they successfully log in.&lt;/p&gt; &lt;p&gt;Now you need a Java class to handle the logout API call. The class that follows captures Keycloak's session ID in your session database and removes the ID when Keycloak calls your logout endpoint:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;@RestController public class IndexController { private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private JdbcTemplate jdbcTemplate; @GetMapping(path = "/") public HashMap index(KeycloakAuthenticationToken authentication, HttpSession httpSession) { SimpleKeycloakAccount account = (SimpleKeycloakAccount) authentication.getDetails(); AccessToken token = account.getKeycloakSecurityContext().getToken(); httpSession.setAttribute(token.getSessionId(), token.getPreferredUsername()); return new HashMap(){{ put("hello", token.getPreferredUsername()); }}; } @PostMapping(path = "/sso-logout", produces = MediaType.APPLICATION_JSON_VALUE) public HashMap logout(@RequestParam("logout_token") String logoutToken) throws Exception { String[] splitString = logoutToken.split("\\."); String body = new String(java.util.Base64.getDecoder().decode(splitString[1])); ObjectMapper mapper = new ObjectMapper(); HashMap bodyMap = mapper.readValue(body, HashMap.class); logger.debug("logging out {}", bodyMap.get("sid")); jdbcTemplate.update("DELETE FROM `spring_session` " + "WHERE `PRIMARY_ID` = (SELECT `PRIMARY_ID` FROM `spring_session_attributes` WHERE `ATTRIBUTE_NAME` = ?)", new Object[] { bodyMap.get("sid") }); return new HashMap(){{ put("status", true); }}; } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, set up Keycloak as your default security configuration:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;@KeycloakConfiguration @EnableGlobalMethodSecurity(prePostEnabled = true) public class KeycloakSecurityConfiguration extends KeycloakWebSecurityConfigurerAdapter { @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception { KeycloakAuthenticationProvider keycloakAuthenticationProvider = keycloakAuthenticationProvider(); keycloakAuthenticationProvider.setGrantedAuthoritiesMapper(new SimpleAuthorityMapper()); auth.authenticationProvider(keycloakAuthenticationProvider); } @Bean @Override protected SessionAuthenticationStrategy sessionAuthenticationStrategy() { return new RegisterSessionAuthenticationStrategy(new SessionRegistryImpl()); } @Bean public org.keycloak.adapters.KeycloakConfigResolver KeycloakConfigResolver() { return new KeycloakSpringBootConfigResolver(); } @Override protected void configure(HttpSecurity http) throws Exception{ super.configure(http); http .logout() .logoutRequestMatcher(new AntPathRequestMatcher("/logout")) .logoutSuccessUrl("http://localhost:8080/auth/realms/external/protocol/openid-connect/logout?redirect_uri=http://localhost:8081/") .and() .authorizeRequests() .antMatchers("/sso-logout**").permitAll() .antMatchers("/").authenticated() .and().csrf().disable(); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You are all set. For the complete source code, please visit &lt;a href="https://github.com/edwin/keycloak-backchannel-logout"&gt;my GitHub respository for Keycloak Backchannel Logout&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Validating single sign-out&lt;/h2&gt; &lt;p&gt;To see whether your application is handling Keycloak logout requests properly, start by logging in. Open your browser and visit your application's URL (&lt;code&gt;localhost:8081&lt;/code&gt;). It should redirect you to Keycloak's login page (&lt;code&gt;localhost:8080&lt;/code&gt;). A successful login brings you back to your application's landing page, displaying your username.&lt;/p&gt; &lt;p&gt;To log out, open a new tab within the same browser as your application's landing page, and enter the following URL:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;http://localhost:8080/auth/realms/external/protocol/openid-connect/logout?redirect_uri=http://localhost:8081/&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This action clears your session ID from Keycloak and your application. If you visit your application URL (&lt;code&gt;localhost:8081&lt;/code&gt;) again, you will have to log in.&lt;/p&gt; &lt;h2&gt;Single sign-out is a Keycloak feature&lt;/h2&gt; &lt;p&gt;This article demonstrated how to implement single sign-out in Java. Applications in any language can handle the REST API call and JWT passed by Keycloak to clean up user sessions.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/07/how-implement-single-sign-out-keycloak-spring-boot" title="How to implement single sign-out in Keycloak with Spring Boot"&gt;How to implement single sign-out in Keycloak with Spring Boot&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Muhammad Edwin</dc:creator><dc:date>2022-12-07T07:00:00Z</dc:date></entry><entry><title>Quarkus 3.0.0.Alpha2 released - Second iteration of our Jakarta EE 10 stream</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-3-0-0-alpha2-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-3-0-0-alpha2-released/</id><updated>2022-12-07T00:00:00Z</updated><published>2022-12-07T00:00:00Z</published><summary type="html">We already presented our Quarkus 3 effort here, here and here. Quarkus 3.0.0.Alpha2 is the continuation of this effort. On the Jakarta EE 10 front, it doesn’t bring anything new, several things are in the works to be integrated in the next Alpha, but it is based on 2.14.3.Final (the...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2022-12-07T00:00:00Z</dc:date></entry><entry><title type="html">How to run OpenTelemetry with WildFly Bootable Jar</title><link rel="alternate" href="http://www.mastertheboss.com/eclipse/eclipse-microservices/how-to-run-opentelemetry-with-wildfly-bootable-jar/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/eclipse/eclipse-microservices/how-to-run-opentelemetry-with-wildfly-bootable-jar/</id><updated>2022-12-06T13:35:14Z</updated><content type="html">This article will teach you how to use the OpenTelemetry API in a sample REST Service which uses WildFly Bootable jar technology as runtime. An overview of OpenTelemetry OpenTelemetry is a set of APIs and libraries that provide a vendor-neutral and open standard for observability in cloud-native applications. It allows developers to instrument their code ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Implementing C++20 atomic waiting in libstdc++</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/06/implementing-c20-atomic-waiting-libstdc" /><author><name>Thomas Rodgers</name></author><id>cd872c55-fbb2-4a55-815c-2adf2ff7e027</id><updated>2022-12-06T07:00:00Z</updated><published>2022-12-06T07:00:00Z</published><summary type="html">&lt;p&gt;The C++ standard library gained some new concurrency features with C++20:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Wait and notify operations on &lt;code&gt;std::atomic&lt;T&gt;&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Semaphores&lt;/li&gt; &lt;li&gt;Latches&lt;/li&gt; &lt;li&gt;Barriers&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;In this article, I will cover the current implementation approach for atomic wait/notify, as these are basis operations required to implement the remaining coordination primitives introduced with C++20. Subsequent articles in this series will cover the details of the other types.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The implementation presented here is considered experimental and the details will almost certainly change in a future version of GCC as we commit to an ABI for these features.&lt;/p&gt; &lt;p&gt;Let's start by taking a look at what the C++ standard says about atomic waiting:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;1 Atomic waiting operations and atomic notifying operations provide a mechanism to wait for the value of an atomic object to change more efficiently than can be achieved with polling. An atomic waiting operation may block until it is unblocked by an atomic notifying operation, according to each function's effects.&lt;/p&gt; &lt;p&gt;[Note 1 : Programs are not guaranteed to observe transient atomic values, an issue known as the A-B-A problem, resulting in continued blocking if a condition is only temporarily met. — end note]&lt;/p&gt; &lt;p&gt;2 [Note 2 : The following functions are atomic waiting operations:&lt;/p&gt; &lt;p&gt;(2.1) — &lt;code&gt;atomic&lt;T&gt;::wait&lt;/code&gt;,&lt;/p&gt; &lt;p&gt;(2.2) — &lt;code&gt;atomic_flag::wait&lt;/code&gt;,&lt;/p&gt; &lt;p&gt;(2.3) — &lt;code&gt;atomic_wait and atomic_wait_explicit&lt;/code&gt;&lt;/p&gt; &lt;p&gt;(2.4) — &lt;code&gt;atomic_flag_wait and atomic_flag_wait_explicit&lt;/code&gt;, and&lt;/p&gt; &lt;p&gt;(2.5) — &lt;code&gt;atomic_ref::wait&lt;/code&gt;. — end note]&lt;/p&gt; &lt;p&gt;3 [Note 3 : The following functions are atomic notifying operations:&lt;/p&gt; &lt;p&gt;(3.1) — &lt;code&gt;atomic&lt;T&gt;::notify_one&lt;/code&gt; and atomic&lt;T&gt;::notify_all,&lt;/p&gt; &lt;p&gt;(3.2) — &lt;code&gt;atomic_flag::notify_one&lt;/code&gt; and atomic_flag::notify_all,&lt;/p&gt; &lt;p&gt;(3.3) — &lt;code&gt;atomic_notify_one and atomic_notify_all&lt;/code&gt;,&lt;/p&gt; &lt;p&gt;(3.4) — &lt;code&gt;atomic_flag_notify_one and atomic_flag_notify_all&lt;/code&gt;, and&lt;/p&gt; &lt;p&gt;(3.5) — &lt;code&gt;atomic_ref&lt;T&gt;::notify_one and atomic_ref&lt;T&gt;::notify_all&lt;/code&gt;. — end note]&lt;/p&gt; &lt;p&gt;4 A call to an atomic waiting operation on an atomic object M is eligible to be unblocked by a call to an atomic notifying operation on M if there exist side effects X and Y on M such that:&lt;/p&gt; &lt;p&gt;(4.1) — the atomic waiting operation has blocked after observing the result of X,&lt;/p&gt; &lt;p&gt;(4.2) — X precedes Y in the modification order of M, and&lt;/p&gt; &lt;p&gt;(4.3) — Y happens before the call to the atomic notifying operation.&lt;/p&gt; &lt;/blockquote&gt; &lt;h2&gt;How can we implement atomic waiting?&lt;/h2&gt; &lt;p&gt;The only universal strategy for implementing atomic waiting is to spin in an atomic load-compare loop. This isn't particularly efficient if the waiter is likely to block for some extended period, but it is advantageous in terms of application responsiveness in many cases to do a bit of spinning before calling into a more expensive operating system level primitive.&lt;/p&gt; &lt;p&gt;libstdc++ implements its spin logic as follows:&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;If supported, this is how we let the CPU or kernel know we are able to yield or relax our spinning:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;inline void __thread_yield() noexcept { #if defined _GLIBCXX_HAS_GTHREADS &amp;&amp; defined _GLIBCXX_USE_SCHED_YIELD __gthread_yield(); #endif } inline void __thread_relax() noexcept { #if defined __i386__ || defined __x86_64__ __builtin_ia32_pause(); #else __thread_yield(); #endif } &lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;We use these constants in the spin loop:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;constexpr auto __atomic_spin_count_1 = 12;&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;constexpr auto __atomic_spin_count_2 = 4;&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;We provide for a pluggable policy in the form of a callable that is invoked as the last step in the spin algorithm. This will be used later in the implementation of timed waiting. The default policy is to exit the spin loop.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; struct __default_spin_policy { bool operator()() const noexcept { return false; } };&lt;/code&gt; &lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The spin loop itself performs the following steps, in order:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Spin for a few iterations evaluating the spin predicate and then performing the &lt;code&gt;relax&lt;/code&gt; operation to either issue a &lt;code&gt;pause&lt;/code&gt; instruction or yield the thread.&lt;/li&gt; &lt;li&gt;Spin for a few iterations and yield the thread if the spin predicate is not satisfied.&lt;/li&gt; &lt;li&gt;Spin until the spin policy indicates we should stop.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;The spin returns true if the predicate is satisfied.&lt;/p&gt; &lt;pre&gt; &lt;code&gt;template&lt;typename _Pred, typename _Spin = __default_spin_policy&gt; bool __atomic_spin(_Pred&amp; __pred, _Spin __spin = _Spin{ }) noexcept { for (auto __i = 0; __i &lt; __atomic_spin_count; ++__i) { if (__pred()) return true; if (__i &lt; __atomic_spin_count_relax) __detail::__thread_relax(); else __detail::__thread_yield(); } while (__spin()) { if (__pred()) return true; } return false; } &lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;A more efficient wait&lt;/h2&gt; &lt;p&gt;On some platforms, the operating system provides an efficient waiting primitive; we should use that facility where available. For Linux, this waiting primitive is futex(2); on Darwin, it is ulock_wait/ulock_wake. If present, these facilities are typically restricted in the type on which you can wait; either a 32-bit int, in the case of a futex, or a 64-bit unsigned int in the case ulock_wait. Clearly, atomic can (and is required by the standard to) support specialization on more types than int32_t or uint64_t, but we'd certainly like to take advantage of the platform-specific wait if it's possible to do so.&lt;/p&gt; &lt;p&gt;libstdc++ implements the low-level details of the platform-specific waiting strategy conditionally as follows. First, we define the fundamental type we can wait efficiently on:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;#ifdef _GLIBCXX_HAVE_LINUX_FUTEX using __platform_wait_t = int; static constexpr size_t __platform_wait_alignment = 4; #else using __platform_wait_t = uint64_t; static constexpr size_t __platform_wait_alignment = __alignof__(__platform_wait_t); #endif &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;libstdc++ defines its own versions of the constants it uses to invoke the futex syscall rather than relying on the presence of &lt;code&gt;&lt;linux/futex.h&gt;&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;#ifdef _GLIBCXX_HAVE_LINUX_FUTEX #define _GLIBCXX_HAVE_PLATFORM_WAIT 1 enum class __futex_wait_flags : int { #ifdef _GLIBCXX_HAVE_LINUX_FUTEX_PRIVATE __private_flag = 128, #else __private_flag = 0, #endif __wait = 0, __wake = 1, __wait_bitset = 9, __wake_bitset = 10, __wait_private = __wait | __private_flag, __wake_private = __wake | __private_flag, __wait_bitset_private = __wait_bitset | __private_flag, __wake_bitset_private = __wake_bitset | __private_flag, __bitset_match_any = -1 }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We invoke the futex syscall to wait as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;__platform_wait(const _Tp* __addr, __platform_wait_t __val) noexcept { auto __e = syscall (SYS_futex, static_cast&lt;const void*&gt;(__addr), static_cast&lt;int&gt;(__futex_wait_flags::__wait_private), __val, nullptr); if (!__e || errno == EAGAIN) return; if (errno != EINTR) __throw_system_error(errno); } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then we invoke the futex syscall to notify one or more waiting threads as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;template&lt;typename _Tp&gt; void __platform_notify(const _Tp* __addr, bool __all) noexcept { syscall (SYS_futex, static_cast&lt;const void*&gt;(__addr), static_cast&lt;int&gt;(__futex_wait_flags::__wake_private), __all ? INT_MAX : 1); } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The current (as of GCC 12) implementation does not support &lt;code&gt;ulock_wait&lt;/code&gt;-based waiting. That (and presumably other similar OS facilities) can be conditionally supported in the future:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;// define _GLIBCX_HAVE_PLATFORM_WAIT and implement __platform_wait() // and __platform_notify() if there is a more efficient primitive supported // by the platform (e.g. __ulock_wait()/__ulock_wake()) which is better than // a mutex/condvar based wait &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;How to handle those types that do not fit in a __platform_wait_t&lt;/h2&gt; &lt;p&gt;To solve this problem, we employ the timeless advice of adding another layer of indirection, of course. Just because we need to atomically modify the contents of an &lt;code&gt;atomic&lt;T&gt;&lt;/code&gt;, we aren't necessarily restricted to implementing wait and notify in terms of that type; we can carry a &lt;code&gt;__platform_wait_t&lt;/code&gt; that is used only for this purpose.&lt;/p&gt; &lt;p&gt;One approach would be to add a new &lt;code&gt;__platform_wait_t&lt;/code&gt; member to &lt;code&gt;atomic&lt;T&gt;&lt;/code&gt;. This would be a fairly expensive approach in terms of ballooning the size of &lt;code&gt;atomic&lt;T&gt;&lt;/code&gt; and pessimizing every use of it. We are also precluded from taking this approach because of ABI stability.&lt;/p&gt; &lt;p&gt;Instead, we create a side table to hold these proxy &lt;code&gt;__platform_wait_t&lt;/code&gt;s and hash into that table by the address of the atomic value.&lt;/p&gt; &lt;h2&gt;Making notify cheaper&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;syscall()&lt;/code&gt; to notify waiting threads is fairly expensive compared to an atomic load. A simple micro-benchmark bears this out -&lt;/p&gt; &lt;pre&gt; &lt;code&gt; ------------------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------------------ BM_empty_notify_checked 3.81 ns 3.81 ns 183296078 BM_empty_notify_syscall 96.9 ns 96.8 ns 7124788 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As this is a micro-benchmark, there are number of caveats to these numbers (and discussion on the subject is a topic for a future article). That said, the cost of blindly making a futex syscall is roughly 30 times that of the optimization outlined here.&lt;/p&gt; &lt;p&gt;Waiters entering the wait syscall are going to pay for an expensive operation anyway, so making them pay a bit extra in terms of an atomic increment is reasonable. Notifiers can then perform an atomic load to determine if the syscall is likely to wake any waiters.&lt;/p&gt; &lt;p&gt;libstdc++'s side table elements could then be defined as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;struct __waiter_pool { __platform_wait_t _M_wait = 0; // Count of waiters __platform_wait_t _M_ver = 0; // Proxy address to use for a futex }; &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;What about platforms that don't provide some low-level efficient wait?&lt;/h2&gt; &lt;p&gt;Wait and notify can be implemented in terms of a mutex and condition variable that the C++ standard library is required to provide, so libstdc++'s side table conditionally carries a mutex and condition_variable for those platforms:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; struct __waiter_pool { #ifdef __cpp_lib_hardware_interference_size static constexpr auto _S_align = hardware_destructive_interference_size; #else static constexpr auto _S_align = 64; #endif alignas(_S_align) __platform_wait_t _M_wait = 0; #ifndef _GLIBCXX_HAVE_PLATFORM_WAIT mutex _M_mtx; #endif alignas(_S_align) __platform_wait_t _M_ver = 0; #ifndef _GLIBCXX_HAVE_PLATFORM_WAIT __condvar _M_cv; #endif // Note entry into a wait void _M_enter_wait() noexcept { __atomic_fetch_add(&amp;_M_wait, 1, __ATOMIC_SEQ_CST); } // Note exit from a wait void _M_leave_wait() noexcept { __atomic_fetch_sub(&amp;_M_wait, 1, __ATOMIC_RELEASE); } // Hello? Is there anybody in there? Just nod if you can hear me. bool _M_waiting() const noexcept { __platform_wait_t __res; __atomic_load(&amp;_M_wait, &amp;__res, __ATOMIC_SEQ_CST); return __res &gt; 0; } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This &lt;code&gt;struct&lt;/code&gt; fits on two hardware cache lines (assuming 64-byte cache lines) and places the atomic counts on different lines.&lt;/p&gt; &lt;p&gt;The same consideration regarding pessimizing notifiers when no thread is waiting applies to platforms that fall back to the mutex/condvar implementation strategy. And the side table itself is a static instance, defined as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;struct __waiter_pool { // ... static __waiter_pool&amp; _S_for(const void* __addr) noexcept { constexpr uintptr_t __ct = 16; static __waiter_pool __w[__ct]; auto __key = (uintptr_t(__addr) &gt;&gt; 2) % __ct; return __w[__key]; } }; &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Putting together the pieces for a wait primitive&lt;/h2&gt; &lt;p&gt;The C++ standard has the following to say about what &lt;code&gt;wait()&lt;/code&gt; should do:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;&lt;code&gt;void wait(T old, memory_order order = memory_order::seq_cst) const noexcept&lt;/code&gt;;&lt;/p&gt; &lt;p&gt;22 Preconditions: order is neither &lt;code&gt;memory_order::release&lt;/code&gt; nor &lt;code&gt;memory_order::acq_rel&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;23 Effects: Repeatedly performs the following steps, in order:&lt;/p&gt; &lt;p&gt;(23.1) — Evaluates &lt;code&gt;load(order)&lt;/code&gt; and compares its value representation for equality against that of old.&lt;/p&gt; &lt;p&gt;(23.2) — If they compare unequal, returns.&lt;/p&gt; &lt;p&gt;(23.3) — Blocks until it is unblocked by an atomic notifying operation or is unblocked spuriously.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;For &lt;code&gt;atomic&lt;T&gt;&lt;/code&gt;s where &lt;code&gt;T&lt;/code&gt; is compatible with (and support is present for) &lt;code&gt;__platform_wait()&lt;/code&gt;, we would perform the following steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Obtain &lt;code&gt;__waiter_pool&lt;/code&gt; entry &lt;code&gt;__w&lt;/code&gt; for the address to be waited&lt;/li&gt; &lt;li&gt;Call &lt;code&gt;__w._M_enter_wait()&lt;/code&gt; to signal that a waiter is available to be notified&lt;/li&gt; &lt;li&gt;Repeatedly perform the following steps, in order: &lt;ol type="A"&gt;&lt;li&gt;Evaluate &lt;code&gt;load(order)&lt;/code&gt; and compare its value representation for equality against that of &lt;code&gt;__old&lt;/code&gt;&lt;/li&gt; &lt;li&gt;If they compare unequal: &lt;ol type="i"&gt;&lt;li&gt;Call &lt;code&gt;__w._M_leave_wait()&lt;/code&gt; to signal that the waiter has left the wait&lt;/li&gt; &lt;li&gt;return&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;li&gt;If they compare equal, then perform the following steps in order: &lt;ol type="i"&gt;&lt;li&gt;Spin for a bit, performing &lt;code&gt;load(order)&lt;/code&gt; to see if value representation changes&lt;/li&gt; &lt;li&gt;If it doesn't change, call &lt;code&gt;__platform_wait(__addr)&lt;/code&gt;, where &lt;code&gt;__addr&lt;/code&gt; is the address to be notified&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;li&gt;Call &lt;code&gt;__w._M_leave_wait()&lt;/code&gt; to signal the waiter has left the wait&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;For &lt;code&gt;atomic&lt;T&gt;&lt;/code&gt;s where &lt;code&gt;T&lt;/code&gt; is not compatible with &lt;code&gt;__platform_wait()&lt;/code&gt; but &lt;code&gt;__platform_wait()&lt;/code&gt; is available, we would perform the following steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Obtain &lt;code&gt;__waiter_pool&lt;/code&gt; entry &lt;code&gt;__w&lt;/code&gt; for the address to be waited&lt;/li&gt; &lt;li&gt;Call &lt;code&gt;__w._M_enter_wait()&lt;/code&gt; to signal that a waiter is available to be notified&lt;/li&gt; &lt;li&gt;Repeatedly perform the following steps, in order: &lt;ol type="A"&gt;&lt;li&gt;Evaluate &lt;code&gt;load(order)&lt;/code&gt; and compare its value representation for equality against that of &lt;code&gt;__old&lt;/code&gt;&lt;/li&gt; &lt;li&gt;If they compare unequal: &lt;ol type="i"&gt;&lt;li&gt;Call &lt;code&gt;__w._M_leave_wait()&lt;/code&gt; to signal that the waiter has left the wait&lt;/li&gt; &lt;li&gt;return&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;li&gt;If they compare equal, then perform the following steps in order: &lt;ol type="i"&gt;&lt;li&gt;Spin for a bit, performing &lt;code&gt;load(order)&lt;/code&gt; to see if value representation changes&lt;/li&gt; &lt;li&gt;If it doesn't change, call &lt;code&gt;__platform_wait(&amp;__w._M_ver)&lt;/code&gt;&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;li&gt;Call &lt;code&gt;__w._M_leave_wait()&lt;/code&gt; to signal that the waiter has left the wait&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;When no &lt;code&gt;__platform_wait()&lt;/code&gt; is available, we would perform the following steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Obtain &lt;code&gt;__waiter_pool&lt;/code&gt; entry &lt;code&gt;__w&lt;/code&gt; for the address to be waited&lt;/li&gt; &lt;li&gt;Call &lt;code&gt;__w._M_enter_wait()&lt;/code&gt; to signal that a waiter is available to be notified&lt;/li&gt; &lt;li&gt;Repeatedly perform the following steps, in order: &lt;ol type="A"&gt;&lt;li&gt;Evaluate &lt;code&gt;load(order)&lt;/code&gt; and compare its value representation for equality against that of &lt;code&gt;__old&lt;/code&gt;&lt;/li&gt; &lt;li&gt;If they compare unequal: &lt;ol type="i"&gt;&lt;li&gt;Call &lt;code&gt;__w._M_leave_wait()&lt;/code&gt; to signal that the waiter has left the wait&lt;/li&gt; &lt;li&gt;return&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;li&gt;If they compare equal, then perform the following steps in order: &lt;ol type="i"&gt;&lt;li&gt;Spin for a bit, performing relaxed load of &lt;code&gt;__w._M_ver&lt;/code&gt; and checking to see if its value changes; if so, exit the spin indicating success&lt;/li&gt; &lt;li&gt;Otherwise, acquire &lt;code&gt;__w._M_mtx&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Atomically load &lt;code&gt;__w._M_ver&lt;/code&gt; and compare its result to the value last observed during the spin loop; if they compare equal, enter &lt;code&gt;__w._M_cv.wait(__w._M_mtx)&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Release &lt;code&gt;__w._M_mtx&lt;/code&gt;&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;li&gt;Call &lt;code&gt;__w._M_leave_wait()&lt;/code&gt; to signal that the waiter has left the wait&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Putting together the pieces for a notify primitive&lt;/h2&gt; &lt;p&gt;The C++ standard has the following to say about what &lt;code&gt;notify_one()&lt;/code&gt; and &lt;code&gt;notify_all()&lt;/code&gt; should do:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;&lt;code&gt;void notify_one() const noexcept;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;25 Effects: Unblocks the execution of at least one atomic waiting operation on *ptr that is eligible to be unblocked (31.6) by this call, if any such atomic waiting operations exist. 26 Remarks: This function is an atomic notifying operation (31.6) on atomic object *ptr.&lt;/p&gt; &lt;p&gt;&lt;code&gt;void notify_all() const noexcept;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;27 Effects: Unblocks the execution of all atomic waiting operations on *ptr that are eligible to be unblocked (31.6) by this call.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;For &lt;code&gt;atomic&lt;T&gt;&lt;/code&gt;s where &lt;code&gt;T&lt;/code&gt; is compatible with (and support is preset for) &lt;code&gt;__platform_notify()&lt;/code&gt;, we would perform the following steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Obtain &lt;code&gt;__waiter_pool&lt;/code&gt; entry&lt;code&gt; __w&lt;/code&gt; for the address to be notified&lt;/li&gt; &lt;li&gt;Check if there are any &lt;code&gt;__w._M_waiting()&lt;/code&gt;, and, if so, call &lt;code&gt;__platform_notify(__addr, __all)&lt;/code&gt;, where: &lt;ul&gt;&lt;li&gt;&lt;code&gt;__all&lt;/code&gt; indicates whether a wake one or wake all is to be performed&lt;/li&gt; &lt;li&gt;&lt;code&gt;__addr&lt;/code&gt; is the address to be notified&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;For &lt;code&gt;atomic&lt;T&gt;&lt;/code&gt;s where &lt;code&gt;T&lt;/code&gt; is not compatible with &lt;code&gt;__platform_notify()&lt;/code&gt; but &lt;code&gt;__platform_notify()&lt;/code&gt; is available, we would perform the following steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Obtain &lt;code&gt;__waiter_pool&lt;/code&gt; entry &lt;code&gt;__w &lt;/code&gt; for the address to be notified&lt;/li&gt; &lt;li&gt;Check if there are any &lt;code&gt;__w._M_waiting&lt;/code&gt;, and, if so, perform the following steps: &lt;ol type="A"&gt;&lt;li&gt;Perform an atomic increment on &lt;code&gt;w._M_ver&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Call &lt;code&gt;__platform_notify(&amp;._M_ver, __all)&lt;/code&gt;, where &lt;code&gt;__all&lt;/code&gt; indicates whether a wake one or wake all is to be performed&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;When no &lt;code&gt;__platform_notify()&lt;/code&gt; is available, we would perform the following steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Obtain &lt;code&gt;__waiter_pool&lt;/code&gt; entry &lt;code&gt;__w&lt;/code&gt; for the address to be notified&lt;/li&gt; &lt;li&gt;Check if there are any &lt;code&gt;__w._M_waiting&lt;/code&gt;, and, if so, perform the following steps: &lt;ol type="A"&gt;&lt;li&gt;Perform an atomic increment on &lt;code&gt;__w._M_ver&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Call &lt;code&gt;__w._M_cv.notify_one/all()&lt;/code&gt;&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Handling the various type and platform choices&lt;/h2&gt; &lt;p&gt;The libstdc++ code to determine whether or not a given type &lt;code&gt;T&lt;/code&gt; supports &lt;code&gt;__platform_wait()&lt;/code&gt; is:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; template&lt;typename _Tp&gt; inline constexpr bool __platform_wait_uses_type #ifdef _GLIBCXX_HAVE_PLATFORM_WAIT = is_scalar_v&lt;_Tp&gt; &amp;&amp; ((sizeof(_Tp) == sizeof(__detail::__platform_wait_t)) &amp;&amp; (alignof(_Tp*) &gt;= __platform_wait_alignment)); #else = false; #endif &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If the platform supports efficient notification, and if &lt;code&gt;sizeof(T)&lt;/code&gt; is the same as &lt;code&gt;__platform_wait_t&lt;/code&gt; and has the same alignment, then &lt;code&gt;T&lt;/code&gt; uses &lt;code&gt;__platform_wait()&lt;/code&gt;. In all other cases, it does not.&lt;/p&gt; &lt;p&gt;In all cases, we will end up doing some sort of wait against the value of a &lt;code&gt;__platform_wait_t&lt;/code&gt;, as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; struct __waiter_pool { // ... void _M_do_wait(const __platform_wait_t* __addr, __platform_wait_t __old) noexcept { #ifdef _GLIBCXX_HAVE_PLATFORM_WAIT __platform_wait(__addr, __old); #else __platform_wait_t __val; __atomic_load(__addr, &amp;__val, __ATOMIC_SEQ_CST); if (__val == __old) { lock_guard&lt;mutex&gt; __l(_M_mtx); _M_cv.wait(_M_mtx); } #endif // __GLIBCXX_HAVE_PLATFORM_WAIT } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And the corresponding notification is implemented as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; struct __waiter_pool { // ... void _M_notify(const __platform_wait_t* __addr, bool __all) noexcept { if (!_M_waiting()) return; #ifdef _GLIBCXX_HAVE_PLATFORM_WAIT __platform_notify(__addr, __all); #else { lock_guard __l(_M_mtx); } if (__all) _M_cv.notify_all(); else _M_cv.notify_one(); #endif } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; the seemingly useless mutex acquisition above is significant, as it ensures that the state of the mutex is synchronized in this thread.&lt;/p&gt; &lt;p&gt;In each wait strategy, there are multiple points where &lt;code&gt;__w._M_leave_wait()&lt;/code&gt; needs to be called. An RAII wrapper type can take care of making sure this always happens at scope exit:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;struct __waiter { __waiter_pool&amp; _M_w; __waiter(__waiter_pool&amp; __w) : _M_w(__w) { _M_w._M_enter_wait(); } ~__waiter() { _M_w._M_leave_wait(); } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In each wait strategy, there is always a &lt;code&gt;__platform_wait_t*&lt;/code&gt; that will be used for determining if a wait has been notified; the particular address is a function of &lt;code&gt;__platform_wait_uses_type&lt;&gt;&lt;/code&gt;. The &lt;code&gt;__waiter&lt;/code&gt; RAII type can take care of initializing itself with the correct address:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;struct __waiter { __waiter_pool&amp; _M_w; __platform_wait_t* _M_addr; template&lt;typename _Up&gt; static __platform_wait_t* _S_wait_addr(const _Up* __a, __platform_wait_t* __b) { if constexpr (__platform_wait_uses_type&lt;_Up&gt;) return reinterpret_cast&lt;__platform_wait_t*&gt;(const_cast&lt;_Up*&gt;(__a)); else return __b; } template&lt;typename _Up&gt; explicit __waiter(const _Up* __addr) noexcept : _M_w(__waiter_pool::_S_for(__addr)) , _M_addr(_S_wait_addr(__addr, &amp;_M_w._M_ver)) { _M_w._M_enter_wait(); } ~__waiter() { _M_w._M_leave_wait(); } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Our wait and notify primitives can now construct a &lt;code&gt;__waiter&lt;/code&gt; &lt;code&gt;__w(__addr)&lt;/code&gt; for any type and get a handle to the A type initialized with the correct address to wait and notify on. However, notify does not need to manipulate that waiter count, so we have two kinds of waiter:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;template&lt;typename _EntersWait&gt; struct __waiter { __waiter_pool&amp; _M_w; __platform_wait_t* _M_addr; template&lt;typename _Up&gt; static __platform_wait_t* _S_wait_addr(const _Up* __a, __platform_wait_t* __b) { if constexpr (__platform_wait_uses_type&lt;_Up&gt;) return reinterpret_cast&lt;__platform_wait_t*&gt;(const_cast&lt;_Up*&gt;(__a)); else return __b; } template&lt;typename _Up&gt; explicit __waiter(const _Up* __addr) noexcept : _M_w(__waiter_pool::_S_for(__addr)) , _M_addr(_S_wait_addr(__addr, &amp;_M_w._M_ver)) { if constexpr (_EntersWait::value) _M_w._M_enter_wait(); } ~__waiter() { if constexpr (_EntersWait::value) _M_w._M_leave_wait(); } }; using __enters_wait = __waiter&lt;std::true_type&gt;; using __bare_wait = __waiter&lt;std::false_type&gt;; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Wait operations use the &lt;code&gt;__enters_wait&lt;/code&gt; type alias, and notify operations use the &lt;code&gt;__bare_wait&lt;/code&gt; type alias.&lt;/p&gt; &lt;p&gt;If we are on a platform that does not support &lt;code&gt;__platform_wait&lt;/code&gt;, it is necessary to communicate the last value seen during the spin loop to the wait. In libstdc++, this is implemented as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;struct __waiter { // ... template&lt;typename _Up, typename _ValFn, typename _Spin = __default_spin_policy&gt; static bool _S_do_spin_v(__platform_wait_t* __addr, const _Up&amp; __old, _ValFn __vfn, __platform_wait_t&amp; __val, _Spin __spin = _Spin{ }) { auto const __pred = [=] { return !__atomic_compare(__old, __vfn()); }; if constexpr (__platform_wait_uses_type&lt;_Up&gt;) { __val == __old; } else // if we implement wait/notify by mutex/condvar we // the current value of _M_w._M_ver, which is the // the address in __addr { __atomic_load(__addr, &amp;__val, __ATOMIC_SEQ_CST); } return __atomic_spin(__pred, __spin); } template&lt;typename _Up, typename _ValFn, typename _Spin = __default_spin_policy&gt; bool _M_do_spin_v(const _Up&amp; __old, _ValFn __vfn, __platform_wait_t&amp; __val, _Spin __spin = _Spin{ }) { return _S_do_spin_v(_M_addr, __old, __vfn, __val, __spin); } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;code&gt;_ValFn&lt;/code&gt; is a unary callable that knows how to return the current value for the address being waited. All functions that receive one have a &lt;code&gt;_v()&lt;/code&gt; suffix.&lt;/p&gt; &lt;p&gt;The primitive wait implementation is:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;struct __waiter { // ... template&lt;typename _Tp, typename _ValFn&gt; void _M_do_wait_v(_Tp __old, _ValFn __vfn) { do { __platform_wait_t __val; if (__base_type::_M_do_spin_v(__old, __vfn, __val)) return; __base_type::_M_w._M_do_wait(__base_type::_M_addr, __val); } while (__atomic_compare(__old, __vfn())); } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The wrapper that &lt;code&gt;atomic&lt;T&gt;::wait&lt;/code&gt; calls into is:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;template&lt;typename _Tp, typename _ValFn&gt; void __atomic_wait_address_v(const _Tp* __addr, _Tp __old, _ValFn __vfn) noexcept { __detail::__enters_wait __w(__addr); __w._M_do_wait_v(__old, __vfn); } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And the corresponding primitive notify function is:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;template&lt;typename _EntersWait&gt; struct __waiter { // ... void _M_notify(bool __all) { if (_M_addr == &amp;_M_w._M_ver) __atomic_fetch_add(_M_addr, 1, __ATOMIC_SEQ_CST); _M_w._M_notify(_M_addr, __all); } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;However, there is a subtle problem with this formulation. If we are proxying notifications for a type not supported by &lt;code&gt;__platform_notify()&lt;/code&gt;, or if &lt;code&gt;__platform_notify()&lt;/code&gt; is not available, the call &lt;code&gt;_M_notify(false)&lt;/code&gt; could wake the incorrect thread. So we add another member to &lt;code&gt;__waiter&lt;/code&gt;, &lt;code&gt;_M_launder&lt;/code&gt;, to capture this:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;template&lt;typename _EntersWait&gt; struct __waiter { __waiter_pool&amp; _M_w; __platform_wait_t* _M_addr; // ... template&lt;typename _Up&gt; explicit __waiter(const _Up* __addr) noexcept : _M_w(__waiter_pool::_S_for(__addr)) , _M_addr(_S_wait_addr(__addr, &amp;_M_w._M_ver)) , _M_laundered(!__platform_wait_uses_type&lt;_Up&gt;) { ... } bool _M_laundered() const noexcept { return _M_addr == &amp;_M_w._M_ver; } void _M_notify(bool __all) { if (_M_laundered()) { __atomic_fetch_add(_M_addr, 1, __ATOMIC_SEQ_CST); __all = true; } _M_w._M_notify(_M_addr, __all); } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And the wrapper that &lt;code&gt;atomic&lt;T&gt;::notify&lt;/code&gt; calls into is:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;template&lt;typename _Tp&gt; void __atomic_notify_address(const _Tp* __addr, bool __all) noexcept { __detail::__bare_wait __w(__addr); __w._M_notify(__all, true); } &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Next time&lt;/h2&gt; &lt;p&gt;C++20 introduces &lt;code&gt;counting_semaphore&lt;/code&gt; and &lt;code&gt;binary_semaphore&lt;/code&gt; (which support &lt;code&gt;blocking acquire()&lt;/code&gt;), non-blocking &lt;code&gt;try_acquire()&lt;/code&gt;, as well as timed &lt;code&gt;try_acquire_for()&lt;/code&gt; and &lt;code&gt;try_acquire_until()&lt;/code&gt;. The next article in this series will look at the implementation of &lt;code&gt;counting_semaphore&lt;/code&gt; and &lt;code&gt;binary_semaphore&lt;/code&gt; and the functionality to implement timed atomic waiting.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/06/implementing-c20-atomic-waiting-libstdc" title="Implementing C++20 atomic waiting in libstdc++"&gt;Implementing C++20 atomic waiting in libstdc++&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Thomas Rodgers</dc:creator><dc:date>2022-12-06T07:00:00Z</dc:date></entry><entry><title>Quarkus 2.14.3.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-2-14-3-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-2-14-3-final-released/</id><updated>2022-12-06T00:00:00Z</updated><published>2022-12-06T00:00:00Z</published><summary type="html">Today, we released Quarkus 2.14.3.Final with a new round of bugfixes and documentation improvements. It is a recommended upgrade for anyone already using 2.14. If you are not already using 2.14, please refer to our migration guide. Full changelog You can get the full changelog of 2.14.3.Final on GitHub. Come...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2022-12-06T00:00:00Z</dc:date></entry><entry><title>How to trace application errors using SystemTap</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/05/trace-application-errors-using-systemtap" /><author><name>Serhei Makarov</name></author><id>b683a5e4-d5ad-47ed-9830-86788b641274</id><updated>2022-12-05T07:00:00Z</updated><published>2022-12-05T07:00:00Z</published><summary type="html">&lt;p&gt;Low-level library functions and kernel system calls on &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; report errors by returning a POSIX error code such as ENOENT or EINVAL. With &lt;a href="https://sourceware.org/systemtap/"&gt;SystemTap&lt;/a&gt;, an open source tracing toolkit maintained by Red Hat, it is possible to look inside the Linux kernel to debug the problem. This article demonstrates how to investigate the cause of an error code using SystemTap with the &lt;code&gt;whythefail.stp&lt;/code&gt; script.&lt;/p&gt; &lt;h2&gt;Limitations of POSIX error codes&lt;/h2&gt; &lt;p&gt;Low-level system libraries on Linux follow the POSIX standard, which defines a &lt;a href="https://man7.org/linux/man-pages/man3/errno.3.html"&gt;list of numerical error codes&lt;/a&gt;. Each error code is associated with an identifier that provides a mnemonic hint about the problem. For instance, error code 22 is identified as EINVAL, denoting an invalid argument to a system call.&lt;/p&gt; &lt;p&gt;The Linux man pages document the error codes returned by each function and the likely circumstances that could produce these error codes. Sometimes, this documentation is sufficient to understand and fix a problem. More often, the range of events that could produce an error code is too complex to document.&lt;/p&gt; &lt;p&gt;For example, suppose we are working on a C program that interacts with the Linux kernel's &lt;code&gt;perf_events&lt;/code&gt; framework through the &lt;code&gt;perf_event_open&lt;/code&gt; system call. When we test the program, the system call fails and returns the EINVAL error code.&lt;/p&gt; &lt;p&gt;Searching for EINVAL in the &lt;a href="https://man7.org/linux/man-pages/man2/perf_event_open.2.html"&gt;manual page for this system call&lt;/a&gt;, we find the following paragraph that gives some hints about possible causes:&lt;/p&gt; &lt;p&gt;"&lt;em&gt;Returned if the specified event is invalid. There are many possible reasons for this. A non-exhaustive list: sample_freq is higher than the maximum setting; the CPU to monitor does not exist; read_format is out of range; sample_type is out of range; the flag's value is out of range; exclusive or pinned set and the event is not a group leader; the event config values are out of range or set reserved bits; the generic event selected is not supported; or there is not enough room to add the selected event.&lt;/em&gt;"&lt;/p&gt; &lt;p&gt;Although this paragraph offers a list of possible reasons for the error, it describes this list as "non-exhaustive." Debugging the program will only show that the system call failed. It will not give any information about whether the cause is one of the reasons on this list or some other cause entirely. The information that would solve this error can be obtained only from Linux kernel internals, beyond the reach of a standard user-space debugger such as GDB.&lt;/p&gt; &lt;h2&gt;How SystemTap probes a system call's implementation&lt;/h2&gt; &lt;p&gt;Fortunately, we can access additional information on an open source operating system in the following ways.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;We could delve into the source code of the Linux kernel or the library producing the error code.&lt;/li&gt; &lt;li&gt;We can also use the SystemTap tracing framework.&lt;/li&gt; &lt;li&gt;SystemTap can gather information from numerous probe points in the Linux kernel and user-space programs. &lt;/li&gt; &lt;li&gt;We can specify the probe points and information-gathering procedures by writing a script in SystemTap's built-in scripting language. SystemTap also includes a &lt;a href="https://sourceware.org/systemtap/examples/"&gt;toolkit of ready-made example scripts&lt;/a&gt; that can answer common questions about a Linux system's behavior. One of these scripts is &lt;a href="https://sourceware.org/systemtap/examples/#general/whythefail.stp"&gt;whythefail.stp&lt;/a&gt;, a powerful tool designed to help find the cause of an unexpected error code by tracing the control-flow path through a system call's implementation.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Gathering information about available probe points&lt;/h2&gt; &lt;p&gt;In our example, we want to trace the path taken through the &lt;code&gt;perf_event_open&lt;/code&gt; syscall. SystemTap can probe almost any statement within functions in the kernel. We can verify the breadth of available probe points with the &lt;code&gt;stap -L&lt;/code&gt; command, which finds all accessible probe points that match a wildcard pattern. We can specify the wildcard patterns in a format similar to file glob patterns in the shell.&lt;/p&gt; &lt;p&gt;Thus, even if we are not aware of the full name of the kernel function implementing &lt;code&gt;perf_event_open&lt;/code&gt;, we can check for &lt;code&gt;kernel.statement&lt;/code&gt; probe points that match the pattern &lt;code&gt;*perf_event_open@*:*&lt;/code&gt;. SystemTap will give the source code locations of these probe points and the list of variables visible at each source code location as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ stap -L 'kernel.statement("*perf_event_open@*:*")' ... kernel.statement("__do_sys_perf_event_open@kernel/events/core.c:12107") $attr_uptr:struct perf_event_attr* $pid:pid_t $cpu:int $group_fd:int $flags:long unsigned int $group_leader:struct perf_event* $output_event:struct perf_event* $attr:struct perf_event_attr $event_file:struct file* $group:struct fd $task:struct task_struct* $event_fd:int $move_group:int $f_flags:int $cgroup_fd:int kernel.statement("__do_sys_perf_event_open@kernel/events/core.c:12108") $attr_uptr:struct perf_event_attr* $pid:pid_t $cpu:int $group_fd:int $flags:long unsigned int $group_leader:struct perf_event* $output_event:struct perf_event* $attr:struct perf_event_attr $event_file:struct file* $group:struct fd $task:struct task_struct* $move_group:int $cgroup_fd:int ...&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: If we cannot find the probe points, the system may not have &lt;a href="https://sourceware.org/elfutils/Debuginfod.html"&gt;debuginfod&lt;/a&gt; installed for retrieving kernel debug information. In that case, we must install the debug information through the legacy method of running the &lt;a href="https://www.man7.org/linux/man-pages/man1/stap-prep.1.html"&gt;stap-prep&lt;/a&gt; script. This script invokes &lt;code&gt;dnf debuginfo-install&lt;/code&gt; on Fedora (or &lt;code&gt;apt&lt;/code&gt; on Debian or Ubuntu) to install kernel debug information and source code packages (e.g. &lt;code&gt;kernel-debuginfo&lt;/code&gt; and &lt;code&gt;kernel-debuginfo-common-*&lt;/code&gt; on Fedora). This alternative method has some drawbacks, including requiring the system to run an up-to-date kernel that matches the kernel debug information package currently available in the package repository. These drawbacks prompted the development of &lt;a href="https://developers.redhat.com/blog/2019/10/14/introducing-debuginfod-the-elfutils-debuginfo-server"&gt;debuginfod&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;stap -L&lt;/code&gt; invocation displays dozens of probe points, one for each statement of the &lt;code&gt;__do_sys_perf_event_open&lt;/code&gt; function. The &lt;a href="https://github.com/torvalds/linux/blob/v5.19/kernel/events/core.c#L12030"&gt;kernel source code&lt;/a&gt; declares this function and assigns it to handle the &lt;code&gt;perf_event_open&lt;/code&gt; system call by invoking the kernel's &lt;code&gt;SYSCALL_DEFINE5&lt;/code&gt; internal convenience macro. The implementation of this macro varies between kernel versions, so the function name could also vary.&lt;/p&gt; &lt;h2&gt;How the whythefail.stp script works&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;whythefail.stp&lt;/code&gt; utility is a script in the SystemTap examples collection that diagnoses an error by tracing the control flow of the function returning that error. The implementation of this script starts with a simple idea: to understand control flow through a function invocation. It is enough to probe every statement in the function. By reporting the sequence of statements, a developer can see which branch every &lt;code&gt;if&lt;/code&gt; statement took and discover where the function exited.&lt;/p&gt; &lt;p&gt;A simplified version of this procedure can be expressed with the SystemTap scripting language as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;probe kernel.statement("__do_sys_perf_event_open@*:*") { tokenize(pp(),"@"); fileline=tokenize("","@") file=tokenize(fileline,":\""); line=tokenize("",":\"") printf("%s[%d] %s:%s $$vars:%s\n", execname(), tid(), file, line, $$vars) }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This code prints a comprehensive description of each statement, including the process and thread responsible for the syscall invocation, the filename and line number of the statement, and the contents of local variables. The calls to &lt;code&gt;tokenize&lt;/code&gt; in the code snippet extract the file name and line number from the &lt;a href="https://sourceware.org/systemtap/tapsets/API-pp.html"&gt;&lt;code&gt;pp()&lt;/code&gt; &lt;em&gt;probe point string&lt;/em&gt;&lt;/a&gt; describing the probe point. After wildcard resolution, this string has a form similar to the probe points produced by &lt;code&gt;stap -L&lt;/code&gt; such as:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;kernel.statement("__do_sys_perf_event_open at kernel/events/core.c:12107")&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Of course, if we trace every invocation of a function, we will see a lot of irrelevant information. Our program might invoke &lt;code&gt;perf_event_open&lt;/code&gt; multiple times and only one of these invocations returns the error code causing the problem. At the same time, it is difficult to filter invocations because we don't know ahead of time whether any given invocation of &lt;code&gt;perf_event_open&lt;/code&gt; is the one that ends up returning the error code.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;whythefail.stp&lt;/code&gt; script solves this dilemma with a strategy called &lt;em&gt;speculative tracing&lt;/em&gt;. A speculative tracer collects information about every invocation of the problematic call (&lt;code&gt;perf_event_open&lt;/code&gt;). At the end of each invocation, the tracer checks the collected data and determines whether it is relevant to the final report, reporting relevant data and discarding irrelevant data. In this case, the relevance criterion is simple: any invocation of &lt;code&gt;perf_event_open&lt;/code&gt; that returns &lt;code&gt;EINVAL&lt;/code&gt; is relevant.&lt;/p&gt; &lt;p&gt;SystemTap supports speculative tracing via the &lt;a href="https://sourceware.org/systemtap/tapsets/speculation.stp.html"&gt;speculation.stp tapset library&lt;/a&gt;, including the following functions:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;speculate(id, msg)&lt;/code&gt; stores a string &lt;code&gt;msg&lt;/code&gt; into a &lt;em&gt;speculation buffer&lt;/em&gt; identified by the label &lt;code&gt;id&lt;/code&gt; until the script can decide whether the information it contains is relevant. For this example, we create a separate speculation buffer for every invocation of &lt;code&gt;perf_event_open&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;commit(id)&lt;/code&gt; outputs the strings accumulated in the speculation buffer labeled &lt;code&gt;id&lt;/code&gt;. For this example, we commit the speculation buffer for an invocation if we find that the invocation returns EINVAL.&lt;/li&gt; &lt;li&gt;&lt;code&gt;discard(id)&lt;/code&gt; discards the strings in the speculation buffer labeled &lt;code&gt;id&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;When we use &lt;code&gt;whythefail.stp&lt;/code&gt; to trace invocations of &lt;code&gt;perf_event_open&lt;/code&gt;, we store a message in the speculation buffer for every statement in &lt;code&gt;__do_sys_perf_event_open&lt;/code&gt;. We commit or discard the speculation at the exit point of the function, traced via the following probe point:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;kernel.function("__do_sys_perf_event_open").return&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Using whythefail.stp to find the error source&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;whythefail.stp&lt;/code&gt; script is a general-purpose utility adapted to our search by providing the following arguments on the SystemTap command line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ stap --example whythefail.stp PROC_OR_KERNEL FUNCTION_NAME CONDITION_EXPRESSION [VARIABLE]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As documented in the script's &lt;a href="https://sourceware.org/systemtap/examples/general/whythefail.stp"&gt;source code&lt;/a&gt;, these arguments take the following meanings:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;PROC_OR_KERNEL&lt;/code&gt; is a &lt;a href="https://sourceware.org/systemtap/langref/langrefse4.html"&gt;SystemTap probe point&lt;/a&gt; prefix identifying the codebase to probe. We specify &lt;code&gt;kernel&lt;/code&gt; to probe the kernel, but the argument could specify a kernel module or user-space process instead.&lt;/li&gt; &lt;li&gt;&lt;code&gt;FUNCTION_NAME&lt;/code&gt; is the function invocation we want to trace.&lt;/li&gt; &lt;li&gt;&lt;code&gt;CONDITION&lt;/code&gt; is the condition evaluated at function return. The &lt;code&gt;whythefail.stp&lt;/code&gt; prints trace data only when &lt;code&gt;CONDITION&lt;/code&gt; evaluates to true.&lt;/li&gt; &lt;li&gt;Optionally, &lt;code&gt;VARIABLE&lt;/code&gt; is a SystemTap expression instructing &lt;code&gt;whythefail.stp&lt;/code&gt; to print an additional value at each statement. The default for &lt;code&gt;VARIABLE&lt;/code&gt; is &lt;code&gt;$$vars&lt;/code&gt;, which prints all of the local variables at each statement.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Optionally, we can add the SystemTap command-line option &lt;code&gt;-c CMD&lt;/code&gt; or &lt;code&gt;-x PID&lt;/code&gt; to trace system call invocations from one particular process. These options are useful for system calls invoked by many other programs simultaneously with the program we debug.&lt;/p&gt; &lt;p&gt;In our example scenario, we invoke &lt;code&gt;whythefail.stp&lt;/code&gt; with a &lt;code&gt;FUNCTION_NAME&lt;/code&gt; of &lt;code&gt;__do_sys_perf_event_open&lt;/code&gt; and a &lt;code&gt;CONDITION&lt;/code&gt; of &lt;code&gt;$return == -22&lt;/code&gt;. Recall that 22 is the numerical error code for EINVAL. We can obtain it by following the chain of includes from &lt;code&gt;/usr/include/errno.h&lt;/code&gt; or by running the &lt;a href="https://helpmanual.io/man1/errno/"&gt;errno&lt;/a&gt; command-line utility. With these arguments, &lt;code&gt;whythefail.stp&lt;/code&gt; traces only invocations of &lt;code&gt;perf_event_open&lt;/code&gt; that finish by returning &lt;code&gt;EINVAL&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ stap --example whythefail.stp kernel __do_sys_perf_event_open "\$return == -22"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We use a backslash to escape the &lt;code&gt;$&lt;/code&gt; dollar sign in &lt;code&gt;$return&lt;/code&gt; to suppress the shell's variable substitution.&lt;/p&gt; &lt;p&gt;The script's output shows the path that the &lt;code&gt;__do_sys_perf_event_open&lt;/code&gt; function took before returning the error code. There will be an entry for each statement, displaying its filename and line number with the contents of local variables, as shown in the following example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;myprogram[20919] kernel function(__do_sys_perf_event_open) $return: -22 myprogram[20919] kernel/events/core.c:12049 $$vars: attr_uptr=0x7ffcd1ef0bc0 pid=0xffffffffffffffff cpu=0x1 group_fd=0xffffffffffffffff flags=0x0 group_leader=0x0 output_event=0x0 event=? sibling=? attr={...} ctx=? gctx=? event_file=0x0 group={...} task=0x0 pmu=? event_fd=? move_group=0x0 err=? f_flags=0x2 cgroup_fd=0xffffffffffffffff myprogram[20919] kernel/events/core.c:12053 $$vars: attr_uptr=0x7ffcd1ef0bc0 pid=0xffffffffffffffff cpu=0x1 group_fd=0xffffffffffffffff flags=0x0 group_leader=0x0 output_event=0x0 event=? sibling=? attr={...} ctx=? gctx=? event_file=0x0 group={...} task=0x0 pmu=? event_fd=? move_group=0x0 err=? f_flags=0x2 cgroup_fd=0xffffffffffffffff myprogram[20919] kernel/events/core.c:12054 $$vars: attr_uptr=0x7ffcd1ef0bc0 pid=0xffffffffffffffff cpu=0x1 group_fd=0xffffffffffffffff flags=0x0 group_leader=0x0 output_event=0x0 event=? sibling=? attr={...} ctx=? gctx=? event_file=0x0 group={...} task=0x0 pmu=? event_fd=? move_group=0x0 err=0x0 f_flags=0x2 cgroup_fd=0xffffffffffffffff myprogram[20919] kernel/events/core.c:12489 $$vars: attr_uptr=? pid=? cpu=? group_fd=? flags=? group_leader=? output_event=? event=? sibling=? attr={...} ctx=? gctx=? event_file=? group={...} task=? pmu=? event_fd=? move_group=? err=? f_flags=? cgroup_fd=?&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Analyzing the Linux source&lt;/h2&gt; &lt;p&gt;We can obtain the source code of &lt;code&gt;kernel/events/core.c&lt;/code&gt; with the &lt;a href="https://developers.redhat.com/blog/2019/10/14/introducing-debuginfod-the-elfutils-debuginfo-server#how_do_i_use_debuginfod_"&gt;debuginfod-find source utility&lt;/a&gt;. When invoking it, we need to know the absolute path of the kernel source as configured in the distribution's source code packages (e.g., &lt;code&gt;kernel-debuginfo-common-*&lt;/code&gt; on Fedora or &lt;code&gt;linux-source-*&lt;/code&gt; on Debian). For example, the absolute path has the prefix &lt;code&gt;/usr/src/debug/kernel-5.19.11/linux-5.19.11-200.fc36.x86_64&lt;/code&gt; on a Fedora system running the kernel version &lt;code&gt;5.19.11-200.fc36.x86_64&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ debuginfod-find source /boot/vmlinuz-5.19.11-200.fc36.x86_64 /usr/src/debug/kernel-5.19.11/linux-5.19.11-200.fc36.x86_64/kernel/events/core.c Downloading from https://debuginfod.fedoraproject.org/ 83040/331982 ~/.cache/debuginfod_client/9b687addfc9de54d0ff36eeb801cadde85fde7b3/source##usr##src##debug##kernel-5.19.11##linux-5.19.11-200.fc36.x86_64##kernel##events##core.c&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, we can look for the line numbers specified in the output of &lt;code&gt;whythefail.stp&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ less -N ~/.cache/debuginfod_client/9b687*/source*kernel##events##core.c ... 12052 /* Do we allow access to perf_event_open(2) ? */ 12053 err = security_perf_event_open(&amp;attr, PERF_SECURITY_OPEN); 12054 if (err) 12055 return err; 12056 12057 err = perf_copy_attr(attr_uptr, &amp;attr); 12058 if (err) 12059 return err; ... 12489 } ...&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Because of inlining and optimization, the kernel debug information is not guaranteed to provide an accessible probe point for every line. We can see that the statement coverage is incomplete if &lt;code&gt;whythefail.stp&lt;/code&gt; outputs warning messages such as the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;WARNING: probe kernel.statement("__do_sys_perf_event_open at kernel/events/core.c:12057") (address 0xffffffffa829e017) registration error [man warning::pass5] (rc -84)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this situation, it is still possible to diagnose the problem. We need to be careful to consider multiple possibilities when interpreting the &lt;code&gt;whythefail.stp&lt;/code&gt; output.&lt;/p&gt; &lt;p&gt;At first glance, it looks as though the error code is coming from the call to &lt;code&gt;security_perf_event_open()&lt;/code&gt;. We test this first hypothesis by running &lt;code&gt;whythefail.stp&lt;/code&gt; again for invocations of &lt;code&gt;security_perf_event_open&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ stap --example whythefail.stp kernel security_perf_event_open "\$return == -22" ... ^C statistics: entry count: 11 exit-miss count: 11 statement count: 22&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The invocation does not yield any output, which suggests that &lt;code&gt;security_perf_event_open()&lt;/code&gt; returned as normal. The statistics report printed when we terminate &lt;code&gt;whythefail.stp&lt;/code&gt;, showing that &lt;code&gt;whythefail.stp&lt;/code&gt; detected 11 function entries and exits that did not satisfy the condition &lt;code&gt;$return == -22&lt;/code&gt; which supports this conclusion.&lt;/p&gt; &lt;p&gt;The original &lt;code&gt;whythefail.stp&lt;/code&gt; output for &lt;code&gt;__do_sys_perf_event_open &lt;/code&gt;stated that &lt;code&gt;err=0x0&lt;/code&gt; (i.e., the value of the local variable &lt;code&gt;err&lt;/code&gt; is still 0) when execution reaches line 12054. This suggests that execution continued to line 12057, one of the lines SystemTap warned us it could not probe. In that case, the error code might be coming from the call to &lt;code&gt;perf_copy_attr()&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We test this second hypothesis by running &lt;code&gt;whythefail.stp&lt;/code&gt; again for invocations of &lt;code&gt;perf_copy_attr&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ stap --example whythefail.stp kernel perf_copy_attr "\$return == -22" ... myprogram[41981] kernel function(perf_copy_attr) $return: -22 myprogram[41981] kernel/events/core.c:11704 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=? myprogram[41981] kernel/events/core.c:11705 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=? myprogram[41981] kernel/events/core.c:11711 $$vars: __ret_gu=? __val_gu=0x0 uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=? myprogram[41981] kernel/events/core.c:11712 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=0x80 ret=0x0 myprogram[41981] kernel/events/core.c:11716 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=0x80 ret=0x0 myprogram[41981] kernel/events/core.c:11718 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=0x80 ret=0x0 myprogram[41981] kernel/events/core.c:11721 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=0x0 myprogram[41981] kernel/events/core.c:11722 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=0x0 myprogram[41981] kernel/events/core.c:11733 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=0x0 myprogram[41981] kernel/events/core.c:11736 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=0x0 myprogram[41981] kernel/events/core.c:11739 $$vars: uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=0x0 myprogram[41981] kernel/events/core.c:11740 $$vars: mask=? uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=0x0 myprogram[41981] kernel/events/core.c:11743 $$vars: mask=0x40001 uattr=0x7ffff30f9140 attr=0xffffa70d8af2be48 size=? ret=0x0 myprogram[41981] kernel/events/core.c:11826 $$vars: uattr=0x7ffff30f9140 attr=? size=? ret=?&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Our program received the error code from this function. These indicated lines of &lt;code&gt;kernel/events/core.c&lt;/code&gt; reveal the cause:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ less -N ~/.cache/debuginfod_client/9b687*/source*kernel##events##core.c ... 11739 if (attr-&gt;sample_type &amp; PERF_SAMPLE_BRANCH_STACK) { 11740 u64 mask = attr-&gt;branch_sample_type; 11741 11742 /* only using defined bits */ 11743 if (mask &amp; ~(PERF_SAMPLE_BRANCH_MAX-1)) 11744 return -EINVAL; ... 11826 }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Evidently, our program passed an invalid parameter value in &lt;code&gt;attr-&gt;branch_sample_type&lt;/code&gt;, where &lt;code&gt;attr&lt;/code&gt; is the &lt;code&gt;struct perf_event_attr&lt;/code&gt; parameter data structure provided when invoking the system call.&lt;/p&gt; &lt;h2&gt;SystemTap and whythefail.stp define system call errors&lt;/h2&gt; &lt;p&gt;This article demonstrated how source code inspection and SystemTap tracing could narrow down the causes of a confusing error code. With the help of &lt;code&gt;whythefail.stp&lt;/code&gt;, we utilized the general information provided by an EINVAL error code and traced the Linux kernel's implementation of the system call to understand which argument was invalid and why. We also illustrated how debugging tools could double as program understanding tools for programmers whose code interacts with an unfamiliar project. When we used &lt;code&gt;whythefail.stp&lt;/code&gt;, our goal was not to diagnose a problem within the kernel itself but to understand the kernel's internals and behavior in more detail than the documentation conveys.&lt;/p&gt; &lt;p&gt;Please comment below if you have any questions. We welcome your feedback!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/05/trace-application-errors-using-systemtap" title="How to trace application errors using SystemTap"&gt;How to trace application errors using SystemTap&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Serhei Makarov</dc:creator><dc:date>2022-12-05T07:00:00Z</dc:date></entry><entry><title>Top Linux resources of 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/12/01/top-linux-resources-2022" /><author><name>Heiker Medina</name></author><id>a3441653-fcf1-46d4-9f2c-edf088e96710</id><updated>2022-12-01T07:00:00Z</updated><published>2022-12-01T07:00:00Z</published><summary type="html">&lt;p&gt;As we head towards the end of 2022, Red Hat Developer is taking a look back at the most intriguing and popular content for the technologies that matter most to our readers. We'll start off with a roundup of the best &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; content of 2022, highlighting some of the most popular stories about Red Hat's flagship Linux distribution.&lt;/p&gt; &lt;h2&gt;Containers&lt;/h2&gt; &lt;p&gt;Join Karan Singh as he explains how to shrink the size of Docker container images using the &lt;a href="https://developers.redhat.com/articles/2022/01/17/reduce-size-container-images-dockerslim"&gt;open source project DockerSlim&lt;/a&gt;. If you want to dive deeper and learn more about Podman, an open source container platform that's an alternative to Docker and supported by Red Hat, review the &lt;a href="https://developers.redhat.com/articles/2022/05/02/podman-basics-resources-beginners-and-experts"&gt;resources for beginners and experts&lt;/a&gt; curated by the Red Hat Developer team.&lt;/p&gt; &lt;p&gt;Another exciting improvement is that &lt;a href="https://developers.redhat.com/articles/2022/03/21/hello-podman-using-net"&gt;.NET can now control Podman&lt;/a&gt;! Tom Deseyn introduces &lt;a href="https://developers.redhat.com/articles/2022/08/01/containerize-net-applications-without-writing-dockerfiles"&gt;dotnet build-image&lt;/a&gt;, a tool that creates Dockerfiles and containerized images. You can use build-image to create an image from a .NET application and push it to a repository.&lt;/p&gt; &lt;h2&gt;GCC and GDB&lt;/h2&gt; &lt;p&gt;Keith Seitz offers an introduction to the &lt;a href="https://developers.redhat.com/articles/2022/01/10/gdb-developers-gnu-debugger-tutorial-part-2-all-about-debuginfo"&gt;debugging information&lt;/a&gt; used to describe compiled code. Bruno Larsen then explains how to &lt;a href="https://developers.redhat.com/articles/2022/06/07/how-debug-stack-frames-and-recursion-gdb"&gt;meet debugging challenges with GDB&lt;/a&gt;, the standard open source debugger for C and C++ programs. Lastly, David Malcolm discusses &lt;a href="https://developers.redhat.com/articles/2022/04/12/state-static-analysis-gcc-12-compiler"&gt; Red Hat's work on static analysis&lt;/a&gt; in the current major release of GCC, GCC 12.&lt;/p&gt; &lt;h2&gt;macOS updates&lt;/h2&gt; &lt;p&gt;Many professional Linux developers and sysadmins use Apple hardware for their personal and dev machines, and will want to run virtual Linux servers on their laptops. Varsha Sharma walks us through &lt;a href="https://developers.redhat.com/articles/2022/05/23/how-install-command-line-tools-mac"&gt;how to install a command that is not from the App Store&lt;/a&gt;, using the popular Helm client as an example. Follow along to see how Red Hat created a &lt;a href="https://developers.redhat.com/articles/2022/10/21/rhel-9-and-single-node-openshift-vms-macos-ventura"&gt;beta&lt;/a&gt; to run virtualized versions of two key technologies, RHEL 9 and single-node OpenShift, using Apple silicon. Lastly, join Arnav Bhati to learn how Red Hat Enterprise Linux VMs can be &lt;a href="https://developers.redhat.com/articles/2022/10/25/how-install-vms-and-ansible-automation-platform-mac-m1"&gt;easily installed on Macs&lt;/a&gt; using UTM.&lt;/p&gt; &lt;h2&gt;Regular expression&lt;/h2&gt; &lt;p&gt;Bob Reselman shows you &lt;a href="https://developers.redhat.com/articles/2022/09/14/beginners-guide-regular-expressions-grep"&gt;how to use regular expressions&lt;/a&gt; to declare a pattern you want to match, and outlines the essential regex building blocks. He explains that if you want a more advanced challenge, you can learn &lt;a href="https://developers.redhat.com/articles/2022/10/13/advanced-regex-capture-groups-lookaheads-and-lookbehinds"&gt;how to capture groups, lookaheads, and lookbehinds&lt;/a&gt;. Another notable piece written by Reselman introduces some more &lt;a href="https://developers.redhat.com/articles/2022/09/16/regex-how-quantifiers-pattern-collections-and-word-boundaries"&gt;advanced syntax&lt;/a&gt;: quantifiers, pattern collections, groups, and word boundaries.&lt;/p&gt; &lt;h2&gt;Product announcements&lt;/h2&gt; &lt;p&gt;In one of our top announcements, we clarified what we call development activities and highlighted some exciting uses of the &lt;a href="https://developers.redhat.com/articles/2022/07/06/what-qualifies-red-hat-developer-subscription-teams"&gt;Developer Subscription for Teams&lt;/a&gt;. Another important piece of news is that organizations that use &lt;a href="https://developers.redhat.com/articles/2022/05/10/access-rhel-developer-teams-subscription"&gt;CentOS Linux offerings&lt;/a&gt; to support developers can now access a RHEL subscription and all the benefits of the Red Hat Developer Program.&lt;/p&gt; &lt;h2&gt;Top resources&lt;/h2&gt; &lt;p&gt;Thanks to the hard work of our editors and writers, we released a series of cheat sheets this year. Our first is &lt;a href="https://developers.redhat.com/cheat-sheets/linux-commands-cheat-sheet-old"&gt;Linux Commands&lt;/a&gt;, which offers Linux commands commonly needed by developers, with explanations and screenshots. Next up is &lt;a href="https://developers.redhat.com/cheat-sheets/intermediate-linux-cheat-sheet"&gt;Intermediate Linux Commands&lt;/a&gt;, which covers Linux commands and executables for developers who use Linux in advanced programming scenarios. Lastly, we recently released &lt;a href="https://developers.redhat.com/cheat-sheets/advanced-linux-commands"&gt;Advanced Linux Commands&lt;/a&gt;, which will take your Linux command knowledge to the next level.&lt;/p&gt; &lt;p&gt;Daniel Walsh, who leads the Podman team at Red Hat, wrote the &lt;a href="https://developers.redhat.com/e-books/podman-action-early-access"&gt;Podman in Action&lt;/a&gt; e-book to help you learn Podman quickly. You'll find easy-to-follow examples that include steps to deploy a complete containerized web service.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/12/01/top-linux-resources-2022" title="Top Linux resources of 2022"&gt;Top Linux resources of 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Heiker Medina</dc:creator><dc:date>2022-12-01T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - December, 1st 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-12-01.html" /><category term="quarkus" /><category term="java" /><category term="jakarta ee" /><category term="wildfly" /><category term="ansible" /><category term="kogito" /><category term="drools" /><author><name>Romain Pelisse</name><uri>https://www.jboss.org/people/romain-pelisse</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-12-01.html</id><updated>2022-12-01T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, java, jakarta ee, wildfly, ansible, kogito, drools"&gt; &lt;h1&gt;This Week in JBoss - December, 1st 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Happy December!&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;Welcome to our new installment of JBoss Editorial! As the end of the year is near, we are packing as much goodness in this issue as possible, for you to have some passionating reading material to enjoy next to your Christmas tree.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_quarkus_still_going_strong"&gt;Quarkus, still going strong&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;On top of the recent releases, of the past few weeks, the Quarkus community took the time to publish an article to present the &lt;a href="https://quarkus.io/blog/quarkus-support-for-aws-lambda-snapstart/"&gt;Quarkus for AWS Lambda Snapstart&lt;/a&gt;. If you have any interest in Quarkus or cloud development, this is certainly a must read!&lt;/p&gt; &lt;p&gt;Last, but not the least, two more, deep articles about Quarkus : one on &lt;a href="https://quarkus.io/blog/reactive-crud-performance-case-study/"&gt;Reactive CRUD performance case study&lt;/a&gt; and the other on &lt;a href="https://quarkus.io/blog/redis-job-queue-reloaded/"&gt;Redis Job Queue - Reloaded&lt;/a&gt; (a followup on Clément’s previous article on &lt;a href="https://quarkus.io/blog/redis-job-queue/"&gt;How to implement a job queue with Redis&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_a_good_time_to_learn_new_or_old_things"&gt;A good time to learn new (or old) things&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;The last two weeks have seen the release of some introductions and presentations articles that are worth mentioning. The first one, my favorite because it talks about an unsung hero of the Wildfly ecosystem, is about : &lt;a href="https://jberet.github.io/jberet-intro/"&gt;Introducing The Java Batch Processing API And JBeret Implementation&lt;/a&gt;. If you have no idea what this is about, please go check it out, this is bound to make your life easier!&lt;/p&gt; &lt;p&gt;After this is definitely this humble article entitled &lt;a href="http://www.mastertheboss.com/java-ee/jakarta-ee/a-maven-starter-for-jakarta-ee-projects/"&gt;A Maven starter for Jakarta EE projects&lt;/a&gt;. Indeed, Maven has been at the heart of Java (and thus JBoss) technology for a long while now (around two decades), so such an introduction, for newcomers and experienced developers alike, is certainly nice to see.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_techbytes"&gt;Techbytes&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;If you need something more involved than a quickstarter, there are two articles coming from the Kogito and Drools ecosystem: &lt;a href="https://blog.kie.org/2022/11/kogito-serverless-workflow-event-formats.html"&gt;Kogito serverless workflow event formats&lt;/a&gt; and &lt;a href="https://blog.kie.org/2022/11/drools-reactive-messaging-processing.html"&gt;Drools reactive messaging processing&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_ansible_support_for_jboss_runtimes"&gt;Ansible support for JBoss runtimes&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;It’s not strictly speaking JBoss community, but I’m too proud of this baby of mine to keep quiet about it. Since over a year, I’ve been part of an initiative to provide better integration between the automation tool Ansible and many of the middleware solutions being developed by the JBoss Community. We are quite to already have Ansible collections (extension for Ansible) that ease the setup of &lt;a href="https://github.com/ansible-middleware/wildfly"&gt;Wildfly&lt;/a&gt;, &lt;a href="https://github.com/ansible-middleware/infinispan"&gt;Infinispan&lt;/a&gt;, &lt;a href="https://github.com/ansible-middleware/keycloak"&gt;Keycloak&lt;/a&gt;, and &lt;a href="https://github.com/ansible-middleware/amq"&gt;AMQ Broker&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;We also provide, for the community, a collection for &lt;a href="https://github.com/ansible-middleware/jws"&gt;Red Hat JBoss Web Server (JWS)&lt;/a&gt; and we are very proud and happy to announce that this collection is now also offered, as tech preview, as part of the last release of Red Hat JWS 5.7: &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_web_server/5.7/html/red_hat_ansible_certified_content_collection_1.2_for_red_hat_jboss_web_server_release_notes/index"&gt;Red Hat Ansible Certified Content Collection 1.2 for Red Hat JBoss Web Server&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you are curious about the potential of those collections and how Ansible can help when you deploy JBoss runtimes, please check this (awesome) demo on &lt;a href="https://events.experiences.redhat.com/widget/redhat/rhaf22/SessionCatalog2022/session/16579300056760019EPY"&gt;Ansible Fest Session Catalog: Managing your Red Hat Middleware estate from the edge to the cloud with Ansible&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_releases_releases_releases"&gt;Releases, releases, releases…​&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Releasing is crucial for Open Source project and releasing often is certainly the mark of healthy one, so it comes with no surprises that the last two weeks have already seen their fair share of releases:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-14-2-final-released/"&gt;Quarkus 2.13.5.Final and 2.14.2.Final&lt;/a&gt; including a fix for &lt;a href="https://access.redhat.com/security/cve/cve-2022-4116"&gt;CVE-2022-4116&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-3-0-0-alpha1-released/"&gt;Quarkus 3.0.0.Alpha1&lt;/a&gt; a first iteration of the Jakarta 10, check it out!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/intellij-quarkus-tools-1.14.0/"&gt;Quarkus Tools for IntelliJ 1.14.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://vertx.io/blog/eclipse-vert-x-4-3-5/"&gt;Eclipse Vert.x 4.3.5&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://galaxy.ansible.com/middleware_automation/infinispan"&gt;Ansible Collection for Infinispan 1.1.1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://galaxy.ansible.com/middleware_automation/jws"&gt;Ansible Collection for JWS 1.2.3&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;&lt;em&gt;That’s all folks! Please join us again in two weeks for another installment of our JBoss editorial!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/romain-pelisse.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Romain Pelisse&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Romain Pelisse</dc:creator></entry><entry><title>How to remotely query indexed caches in Data Grid 8</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/11/30/remotely-query-indexed-caches-data-grid-8" /><author><name>Alexander Barbosa Ayala</name></author><id>5cab99e0-6a2c-4bf4-9130-268868f0c3d4</id><updated>2022-11-30T07:00:00Z</updated><published>2022-11-30T07:00:00Z</published><summary type="html">&lt;p&gt;The &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/data-grid"&gt;Red Hat Data Grid&lt;/a&gt; is a hosted data storage platform that offers different levels of caching for fast access to data in memory. Well-chosen indexes allow the data store to fetch results faster than non-indexed caches. This article demonstrates how to create indexes in Data Grid and use them in a &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; application built on &lt;a href="https://developers.redhat.com/topics/spring-boot"&gt;Spring Boot&lt;/a&gt;. Then we will run and test the application in a &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; on &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Understanding indexed cache structure&lt;/h2&gt; &lt;p&gt;To use indexing, you need to define the indexed entity both in Data Grid and on the application side. The example in this article uses a &lt;code&gt;Book&lt;/code&gt; entity, shown in Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig1_23.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig1_23.png?itok=e2VVO2k2" width="141" height="121" alt="The Book object contains three fields for which we create indexes." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The Book object contains three fields for which we create indexes. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;The &lt;code&gt;Book&lt;/code&gt; structure needs to be mapped on either side of the communication, as a Java object in the application (&lt;code&gt;Book.java&lt;/code&gt;) and as a &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html/cache_encoding_and_marshalling/cache-encoding#protobuf-encoding_storage-formats"&gt;Protocol Buffers (protobuf) schema&lt;/a&gt; in the cache. Figure 2 shows the relationship between all the components using the cache.&lt;/p&gt; &lt;p&gt; &lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/DataGrid-Fig2.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/DataGrid-Fig2.png?itok=oYNEMgWX" width="600" height="235" alt="A relational diagram of the Spring Boot application and Data Grid." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Both the Spring Boot application and Data Grid define the structure of the Book. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt; &lt;/p&gt; &lt;p&gt;The &lt;code&gt;Book.java&lt;/code&gt; class defines the Book entity fields using the &lt;code&gt;@Protodoc&lt;/code&gt; and &lt;code&gt;@Protofiled&lt;/code&gt; annotations as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;package com.redhat.dg8remote.controller; ... @ProtoDoc("@Indexed") public class Book { @ProtoDoc("@Field(index=Index.YES, analyze = Analyze.YES, store = Store.NO)") @ProtoField(number = 1) String title; @ProtoDoc("@Field(index=Index.YES, analyze = Analyze.YES, store = Store.NO)") @ProtoField(number = 2) String description; @ProtoDoc("@Field(index=Index.YES, analyze = Analyze.YES, store = Store.NO)") @ProtoField(number = 3, defaultValue = "0") int publicationYear; @ProtoFactory Book(String title, String description, int publicationYear) { this.title = title; this.description = description; this.publicationYear = publicationYear; } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;book.proto&lt;/code&gt; schema file defines the same fields as &lt;code&gt;Book.java&lt;/code&gt; does, but using the syntax for a protobuf schema:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;syntax = "proto2"; package book_sample; /** * @Indexed */ message Book { /** * @Field(index=Index.YES, analyze = Analyze.YES, store = Store.NO) */ optional string title = 1; /** * @Field(index=Index.YES, analyze = Analyze.YES, store = Store.NO) */ optional string description = 2; /** * @Field(index=Index.YES, analyze = Analyze.YES, store = Store.NO) */ optional int32 publicationYear = 3 [default = 0]; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To use indexes, you also need to make changes in the XML definition of the Data Grid cache.&lt;/p&gt; &lt;p&gt;First, you need to add an &lt;code&gt;&lt;indexing&gt;&lt;/code&gt; element. This element causes the data marshaling process to use the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html/cache_encoding_and_marshalling/marshalling_user_types#protostream_marshalling"&gt;ProtoStream library&lt;/a&gt; to handle protobufs. Then, define the  &lt;code&gt;&lt;indexed-entity&gt;&lt;/code&gt; element referring to the &lt;code&gt;&lt;package&gt;.&lt;entity-name&gt;&lt;/code&gt; structure. &lt;/p&gt; &lt;p&gt;For the current article the indexed cache should be configured as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &lt;replicated-cache name="books" mode="SYNC" statistics="true"&gt; &lt;indexing enabled="true"&gt; &lt;indexed-entities&gt; &lt;indexed-entity&gt;book_sample.Book&lt;/indexed-entity&gt; &lt;/indexed-entities&gt; &lt;/indexing&gt; &lt;/replicated-cache&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that the default cache &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html/cache_encoding_and_marshalling/cache-encoding#encoding-caches-protostream_storage-formats"&gt;encoding&lt;/a&gt; is &lt;code&gt;application/x-protostream. &lt;/code&gt;Therefore, no additional elements are required for this cache configuration.&lt;/p&gt; &lt;h2&gt;The remote query application&lt;/h2&gt; &lt;p&gt;The current query demo application is based on the example provided in the Data Grid documentation section &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html-single/querying_data_grid_caches/index#querying-hot-rod_query-remote"&gt;Querying caches from Hot Rod Java clients&lt;/a&gt;. I have adapted this application and configured it to run as a Spring Boot application. The application can run standalone or be deployed in a containerized environment such as OpenShift. The code source can be found in the &lt;a href="https://github.com/alexbarbosa1989/dg8remote/tree/openshift/src/main/java/com/redhat/dg8remote"&gt;dg8remote&lt;/a&gt; demo project on GitHub.&lt;/p&gt; &lt;p&gt;The application defines three classes for remote query and entity definition. A fourth class implements data marshaling (Figure 3).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig3_8.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig3_8.png?itok=w5j4CWH-" width="287" height="461" alt="The example application defines three classes for queries and one class for data marshaling." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: The example application defines three classes for queries and one class for data marshaling. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;The classes have the following purposes:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://github.com/alexbarbosa1989/dg8remote/blob/openshift/src/main/java/com/redhat/dg8remote/controller/Book.java"&gt;Book.java&lt;/a&gt;: Contains the fields for the Book entity. Each field has &lt;code&gt;@Protodoc&lt;/code&gt; and &lt;code&gt;@Protofield&lt;/code&gt; annotations for indexing purposes.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/alexbarbosa1989/dg8remote/blob/openshift/src/main/java/com/redhat/dg8remote/controller/RemoteQueryInitializer.java"&gt;RemoteQueryInitializer.java&lt;/a&gt;: An interface that contains the protobuf schema details, such as a &lt;code&gt;Book&lt;/code&gt; class reference for automatic proto file generation, package name, proto file name, and path.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/alexbarbosa1989/dg8remote/blob/openshift/src/main/java/com/redhat/dg8remote/controller/RemoteQuery.java"&gt;RemoteQuery.java&lt;/a&gt;: Contains the exposed REST service that returns the query results. The constructor uploads the generated &lt;code&gt;book.proto&lt;/code&gt; file in the Remote Data Grid instance. This class also tells the compiler to generate a &lt;code&gt;RemoteQueryInitializerImp&lt;/code&gt; schema.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/alexbarbosa1989/dg8remote/blob/openshift/src/main/java/com/redhat/dg8remote/InfinispanConfiguration.java"&gt;InfinispanConfiguration.java&lt;/a&gt;: Adds a marshaller, which is needed in the client to serialize the application's object.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Running the remote query service&lt;/h2&gt; &lt;p&gt;For the current demo, deploy the Data Grid cache cluster and the remote query service on OpenShift. The caches and the service are in separate projects, just like the original version of the application described in the article &lt;a href="https://developers.redhat.com/articles/2022/05/31/integrate-spring-boot-application-red-hat-data-grid"&gt;Integrate a Spring Boot application with Red Hat Data Grid&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Environment details&lt;/h3&gt; &lt;p&gt;I used the following versions of the components that make up this example:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Red Hat Data Grid 8.3&lt;/li&gt; &lt;li&gt;Red Hat OpenShift 4.10&lt;/li&gt; &lt;li&gt;Spring Boot 2.7.2&lt;/li&gt; &lt;li&gt;Java 11&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Defining the Data Grid cluster custom resource&lt;/h2&gt; &lt;p&gt;The previous article explains how the Data Grid cluster is generated using an Operator. We have to make one change in our example to expose the cluster through the LoadBalancer. Here is how our configuration looks:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: infinispan.org/v1 kind: Infinispan metadata: name: infinispan-test namespace: dgtest spec: expose: type: LoadBalancer service: type: DataGrid replicas: 2&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Creating the book cache&lt;/h2&gt; &lt;p&gt;To create the cache, go to the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html-single/data_grid_operator_guide/index#connecting-console_clients"&gt;Data Grid Web Console&lt;/a&gt; in a browser, then create a custom cache named &lt;code&gt;books&lt;/code&gt; using the following JSON code. Include the &lt;code&gt;book_sample.Book&lt;/code&gt; indexed entity as shown. Figure 4 shows where to enter the JSON.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;{ "replicated-cache": { "mode": "SYNC", "statistics": true, "indexing": { "enabled": true, "indexed-entities": [ "book_sample.Book" ] } } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Finish by clicking the &lt;strong&gt;Create&lt;/strong&gt; button:&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig4_6.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig4_6.png?itok=OxmLvCp0" width="600" height="312" alt="Enter the JSON configuration and create the books cache." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Enter the JSON configuration and create the books cache. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;There are other ways to create caches, detailed in &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html-single/data_grid_operator_guide/index#creating-caches"&gt;Data Grid Documentation&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Configuring the application to use the data grid cluster&lt;/h2&gt; &lt;p&gt;Clone the remote query service project:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ git clone -b openshift https://github.com/alexbarbosa1989/dg8remote&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Refer to &lt;a href="https://developers.redhat.com/articles/2022/05/31/integrate-spring-boot-application-red-hat-data-grid"&gt;Integrate a Spring Boot application with Red Hat Data Grid&lt;/a&gt; and follow the instructions in &lt;a href="https://developers.redhat.com/articles/2022/05/31/integrate-spring-boot-application-red-hat-data-grid#gather_relevant_data_grid_cluster_data"&gt;Gather relevant Data Grid cluster data&lt;/a&gt; and &lt;a href="https://developers.redhat.com/articles/2022/05/31/integrate-spring-boot-application-red-hat-data-grid#how_to_deploy_the_spring_boot_project"&gt;How to deploy the Spring Boot project&lt;/a&gt;. The &lt;code&gt;application.properties&lt;/code&gt; file should look like the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# context-path server.servlet.context-path=/redhat # allow all endoints exposure management.endpoints.web.exposure.include=* # Connection infinispan.remote.server-list=181.123.123.123:11222 infinispan.remote.client-intelligence=BASIC # Authentication infinispan.remote.use-auth=true infinispan.remote.sasl-mechanism=BASIC infinispan.remote.auth-realm=default infinispan.remote.auth-server-name=infinispan-test infinispan.remote.auth-username=developer infinispan.remote.auth-password=ygwaioo0XWhxMtBU infinispan.remote.sasl_properties.javax.security.sasl.qop=auth # Encryption infinispan.remote.sni_host_name=181.123.123.123 infinispan.remote.trust_store_file_name=/mnt/secrets/truststore.jks infinispan.remote.trust_store_password=password infinispan.remote.trust_store_type=jks # Marshalling infinispan.remote.marshaller=org.infinispan.commons.marshall.ProtoStreamMarshaller infinispan.remote.java-serial-allowlist=com.*,org.* infinispan.remote.java-serial-whitelist=com.*,org.* infinispan.client.hotrod.marshaller=org.infinispan.commons.marshall.ProtoStreamMarshaller infinispan.client.hotrod.java_serial_allowlist=com.*,org.* infinispan.client.hotrod.java_serial_whitelist=com.*,org.*&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Because we are using the LoadBalancer, the &lt;code&gt;infinispan.remote.server-list&lt;/code&gt; property has an assigned external IP address for the data grid service, exposed by OpenShift, instead of the SVC name rendered by DNS that appeared in the original version of the application. You can the IP address using the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc get svc |grep external infinispan-test-external LoadBalancer 10.20.21.22 181.123.123.123 11222:30890/TCP 22m &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Deploying the remote query application in OpenShift&lt;/h2&gt; &lt;p&gt;After updating the properties file, it's time to &lt;a href="https://developers.redhat.com/articles/2022/05/31/integrate-spring-boot-application-red-hat-data-grid#create_a_new_project_in_openshift_for_spring_boot_application_deployment"&gt;create a new OpenShift project&lt;/a&gt;. You can create it in the same OpenShift cluster where the Data Grid cluster is running or in a different remote cluster. A remote cluster can be used because you have external access to the Data Grid cluster via LoadBalancer:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc new-project springboot-test&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now, you can &lt;a href="https://developers.redhat.com/articles/2022/05/31/integrate-spring-boot-application-red-hat-data-grid#deploy_the_spring_boot_application"&gt;deploy the remote query application&lt;/a&gt;. Take care to run the following command from the application's new OpenShift project, which you can get into using the &lt;code&gt;oc project springboot-test&lt;/code&gt; command. Compile and deploy the application as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ mvn clean fabric8:deploy -Popenshift&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Finally, create a secret that will store the Keystore generated in the previous step:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc create secret generic truststore-secret --from-file=truststore.jks $ oc set volume dc/hotrodspringboot --add --name=truststore-secret -m /mnt/secrets/ -t secret --secret-name=truststore-secret --default-mode='0755'&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Testing the remote query&lt;/h2&gt; &lt;p&gt;Once you have deployed the application, you can test the remote query integration. You must get the exposed route for the service by using the &lt;code&gt;oc get routes&lt;/code&gt; command. Here is the output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc get routes NAME HOST/PORT remote-query remote-query-springboot-test.openshiftcluster.com PATH SERVICES PORT TERMINATION WILDCARD remote-query 8080 None&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Send a request to the REST endpoint for the service using the &lt;code&gt;curl&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ curl -X GET http://remote-query-springboot-test.openshiftcluster.com/redhat/query-cache/ - Book title 10 - 2022% &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Let's understand what happened when you invoked the&lt;code&gt;/query-cache&lt;/code&gt; service. First, as mentioned earlier, the Data Grid cluster imported the &lt;code&gt;book.proto&lt;/code&gt; structure to get the data structure needed to process the request from the remote query service. The &lt;code&gt;proto.book&lt;/code&gt; file was generated when you compiled the &lt;code&gt;RemoteQueryInitializer.java&lt;/code&gt; class. The &lt;code&gt;RemoteQuery.java&lt;/code&gt; constructor uploads the &lt;code&gt;proto.book&lt;/code&gt; file into the Data Grid cluster. The following code in the &lt;code&gt;RemoteQuery&lt;/code&gt; class puts that generated schema into the Data Grid cluster's cache data structure:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;public class RemoteQuery { ... @Autowired public RemoteQuery(RemoteCacheManager cacheManager) { ... GeneratedSchema schema = new RemoteQueryInitializerImpl(); metadataCache.put(schema.getProtoFileName(), schema.getProtoFile()); } ... }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Having the schema mapped on both sides, as shown in Figure 2, the service uploads a set of &lt;code&gt;Book&lt;/code&gt; objects into a Map and stores them in the Data Grid cache.&lt;/p&gt; &lt;p&gt;Data Grid executes the query and put the resultset into a &lt;code&gt;List&lt;/code&gt; of &lt;code&gt;Book&lt;/code&gt; objects. This query gets all books that contain the characters '&lt;code&gt;10'&lt;/code&gt; in their titles:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt; QueryFactory queryFactory = Search.getQueryFactory(remoteCache); Query&lt;Book&gt; query = queryFactory.create("FROM book_sample.Book WHERE title:'10'"); List&lt;Book&gt; list = query.execute().list();&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Our example performs both the data load into the cache and the query in the same &lt;code&gt;/query-cache&lt;/code&gt; service for the purpose of simplicity. However, each step could also be performed in different services, depending on the use case and application architecture.&lt;/p&gt; &lt;p&gt;There are also multiple ways to perform queries. The Ickle query syntax is explained in the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html/querying_data_grid_caches/ickle-query-language#doc-wrapper"&gt;Data Grid documentation&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Adding indexes to Data Grid is easy and beneficial&lt;/h2&gt; &lt;p&gt;This article demonstrated how you can easily add Indexes to Data Grid. Indexed caches offer benefits such as:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Remote queries&lt;/li&gt; &lt;li&gt;Supports more complex data based on entities with multiple fields.&lt;/li&gt; &lt;li&gt;A broad range of query alternatives, shaped according to each use case.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The official &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.3/html/querying_data_grid_caches/indexing-caches"&gt;product documentation&lt;/a&gt; contains details about indexing in Red Hat Data Grid. Please comment below if you have questions. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/11/30/remotely-query-indexed-caches-data-grid-8" title="How to remotely query indexed caches in Data Grid 8"&gt;How to remotely query indexed caches in Data Grid 8&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Alexander Barbosa Ayala</dc:creator><dc:date>2022-11-30T07:00:00Z</dc:date></entry></feed>
